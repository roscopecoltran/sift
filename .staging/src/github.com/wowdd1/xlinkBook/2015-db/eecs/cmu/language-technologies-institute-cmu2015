LTI11344 | Machine Learning in Practice | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11344&SEMESTER=S15 | instructors:Rose, Carolyn description:Machine Learning is concerned with computer programs that enable the behavior of a computer to be learned from examples or experience rather than dictated through rules written by hand.  It has practical value in many application areas of computer science such as on-line communities and digital libraries.  This class is meant to teach the practical side of machine learning for applications, such as mining newsgroup data or building adaptive user interfaces.  The emphasis will be on learning the process of applying machine learning effectively to a variety of problems rather than emphasizing an understanding of the theory behind what makes machine learning work.  This course does not assume any prior exposure to machine learning theory or practice. In the first 2/3 of the course, we will cover a wide range of learning algorithms that can be applied to a variety of problems.  In particular, we will cover topics such as decision trees, rule based classification, support vector machines, Bayesian networks, and clustering. In the final third of the class, we will go into more depth on one application area, namely the application of machine learning to problems involving text processing, such as information retrieval or text categorization.
LTI11345 | Undergrad Independent Study | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11345&SEMESTER=S15 | description:None
LTI11390 | LTI Minor Project - Juniors | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11390&SEMESTER=S15 | instructors:Black, Alan description:None
LTI11411 | Natural Language Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11411&SEMESTER=S15 | instructors:Black, Alan Dyer, Christopher Wilson, Shomir prereq:15122 description:This course will introduce students to the highly interdisciplinary area of Artificial Intelligence known alternately as Natural Language Processing (NLP) and Computational Linguistics. The course aims to cover the techniques used today in software that does useful things with text in human languages like English and Chinese. Applications of NLP include automatic translation between languages, extraction and summarization of information in documents, question answering and dialog systems, and conversational agents. This course will focus on core representations and algorithms, with some time spent on real-world applications. Because modern NLP relies so heavily on Machine Learning, we'll cover the basics of discrete classification and probabilistic modeling as we go. Good computational linguists also know about Linguistics, so topics in linguistics (phonology, morphology, and syntax) will be covered when fitting. From a software engineering perspective, there will be an emphasis on rapid prototyping, a useful skill in many other areas of Computer Science. In particular, we will introduce some high-level languages (e.g., regular expressions and Dyna) and some scripting languages (e.g., Python and Perl) that can greatly simplify prototype implementation.
LTI11441 | Machine Learning for Text Mining | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11441&SEMESTER=S15 | instructors:Yang, Yiming description:This course provides a comprehensive introduction to the theory and implementation of algorithms for organizing and searching large text collections. The first half of the course studies text search engines for enterprise and Web environments; the open-source Indri search engine is used as a working example. The second half studies text mining techniques such as clustering, categorization, and information extraction. Programming assignments give hands-on experience with document ranking algorithms, categorizing documents into browsing hierarchies, and related topics.
LTI11442 | Search Engines | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11442&SEMESTER=S15 | instructors:Callan, James description:This course studies the theory, design, and implementation of text-based search engines. The core components include statistical characteristics of text, representation of information needs and documents, several important retrieval models, and experimental evaluation. The course also covers common elements of commercial search engines, for example, integration of diverse search engines into a single search service ("federated search", "vertical search"), personalized search results, diverse search results, and sponsored search. The software architecture components include design and implementation of large-scale, distributed search engines.
LTI11443 | Machine Learning for Text Analysis | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11443&SEMESTER=F14 | instructors:Yang, Yiming prereq:15213 and 21325 and 21241 description:(Previously Scalable Analytics)This is a full-semester course (12 units), intended for students in professional PhD/master programs and undergraduates who meet the pre-requisites.  Replacing the 2nd half of 11-641/11-441 (Search Engines and Web Mining), this new course offers a blend of core theory, important applications, and implementation of scalable analytic techniques.  Specifically, it covers high-dimensional data representation, dimensionality reduction, clustering, collaborative filtering, large scale classification, learning to rank, link analysis, statistical significance tests, and more. Homework assignments give hands-on experiences to students by implementing representative algorithms, conducting empirical evaluations, and exercising the main concepts taught in the course. Prerequisites ?	Data structures & algorithms (e.g. 15-213) (required) ?	Matrix or Linear Algebra (e.g. 21-241 or 21-341) (required)  ?	Basic Probability and Statistics (e.g. 21-325) (required) ?	15-451, Algorithm Design and Analysis (not required but helpful) ?	10-601 or 10-701, Machine Learning (not required but helpful) For CMU CS undergraduates, all of the required courses need to be completed before or during the junior year; for MS students, equivalent background is required.
LTI11465 | Special Topics: Digital Signal Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11465&SEMESTER=S15 | instructors:Ramakrishnan, Bhiksha description:None
LTI11490 | LTI Minor Project - Seniors | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11490&SEMESTER=S15 | instructors:Black, Alan description:None
LTI11492 | Speech Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11492&SEMESTER=F14 | instructors:Black, Alan description:to be determined by the department.
LTI11590 | LTI Minor Project - Advanced | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11590&SEMESTER=S15 | instructors:Black, Alan description:None
LTI11601 | Coding Boot-Camp | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11601&SEMESTER=S15 | instructors:Starzl, Ravi description:This is a masters-level course for students who have a CS undergraduate background but want to solidify their coding and algorithm skills. The course will be taught in Java, and will take a stratified approach to teaching material including fundamental coding, algorithms, coding/algorithmic problem solving, and agile development methodology.
LTI11611 | Natural Language Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11611&SEMESTER=S15 | instructors:Black, Alan Dyer, Christopher Wilson, Shomir description:None
LTI11630 | MCDS Practicum: MCDS Practicum | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11630&SEMESTER=M15 | instructors:Nyberg, Eric Tomasic, Anthony description:The MCDS Practicum course is used for recording CDS students summer internship units that are in the Analytics track of the program.  Section A is used for 7-month internship opportunities Section B is used for Returning Fall Analytic students who DO NOT attain a 7-mo Internship
LTI11631 | Seminar in Data Science: Seminar in Data Science | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11631&SEMESTER=S15 | instructors:Nyberg, Eric Tomasic, Anthony description:This course provides the student with a basic understanding of Data Science as an emerging scientific discipline, with interdisciplinary perspectives from computer science, business, and information policy / security. Students will read and discuss relevant publications, and attend presentations by guest speakers. Grading will be based on homework assignments related to the material covered in class sessions.
LTI11632 | Data Science "Analytics" Capstone Independent Study Outcomes: Data Science Analytics Capstone Independent Study Process &amp; Outcomes | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11632&SEMESTER=M15 | instructors:Nyberg, Eric Tomasic, Anthony description:The MCDS-Capstone course is the final large team project for MCDS master degree students. Students take 08-742 as a combined capstone course for process & outcomes. This process & outcome course evaluates the project team's use of software engineering methodology and evaluates the outcomes of the project.
LTI11633 | MCDS Independent Study: MCDS Independent Study | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11633&SEMESTER=M15 | instructors:Nyberg, Eric description:An independent study course is designed by the student to cover study of a particular area of interest too the student and is used when there is no formal course available in that subject area.
LTI11634 | Data Science System Capstone: Data Science Systems Capstone | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11634&SEMESTER=M15 | instructors:Gibson, Garth Sakr, Majd description:MCDS "Systems" Track students generally interview for a summer internship during the Fall and Spring semesters. This course is used to record the internship units for there 7-month internship opportunity during the Summer/Fall semesters. Section B of this course is for returning MCDS students in the "Systems" Track Capstone Project done as an independent study on campus
LTI11641 | Machine Learning for Text Mining | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11641&SEMESTER=S15 | instructors:Yang, Yiming description:TBA
LTI11642 | Search Engines | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11642&SEMESTER=S15 | instructors:Callan, James description:This course studies the theory, design, and implementation of text-based search engines. The core components include statistical characteristics of text, representation of information needs and documents, several important retrieval models, and experimental evaluation. The course also covers common elements of commercial search engines, for example, integration of diverse search engines into a single search service ("federated search", "vertical search"), personalized search results, diverse search results, and sponsored search. The software architecture components include design and implementation of large-scale, distributed search engines.
LTI11643 | Machine Learning for Text Analysis | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11643&SEMESTER=F14 | instructors:Yang, Yiming prereq:15213 and 21325 and 21241 description:(Previously Scalable Analytics)This is a full-semester course (12 units), intended for students in professional PhD/master programs and undergraduates who meet the pre-requisites.  Replacing the 2nd half of 11-641/11-441 (Search Engines and Web Mining), this new course offers a blend of core theory, important applications, and implementation of scalable analytic techniques.  Specifically, it covers high-dimensional data representation, dimensionality reduction, clustering, collaborative filtering, large scale classification, learning to rank, link analysis, statistical significance tests, and more. Homework assignments give hands-on experiences to students by implementing representative algorithms, conducting empirical evaluations, and exercising the main concepts taught in the course. Prerequisites ?	Data structures & algorithms (e.g. 15-213) (required) ?	Matrix or Linear Algebra (e.g. 21-241 or 21-341) (required)  ?	Basic Probability and Statistics (e.g. 21-325) (required) ?	15-451, Algorithm Design and Analysis (not required but helpful) ?	10-601 or 10-701, Machine Learning (not required but helpful) For CMU CS undergraduates, all of the required courses need to be completed before or during the junior year; for MS students, equivalent background is required.
LTI11661 | Language and Statistics | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11661&SEMESTER=S15 | instructors:Rosenfeld, Ronald description:Language technologies (search, text mining, information retrieval, speech recognition, machine translation, question answering, biological sequence analysis...) are at the forefront of this century's information revolution.  In addition to their use of machine learning, these technologies rely centrally on classic statistical estimation techniques.   Yet most CS and engineering undergraduate programs do not prepare students in this area beyond an introductory prob&stats course.  This course is designed to plug this hole.  The goal of "Language and Statistics" is to ground the data-driven techniques used in language technologies in sound statistical methodology.   We start by formulating various language technology problems in both an information theoretic framework (the source-channel paradigm) and a Bayesian framework (the Bayes classifier).  We then discuss the statistical properties of words, sentences, documents and whole languages, and the computational formalisms used to represent language.  These discussions naturally lead to specific concepts in statistical estimation.  Topics include: Zipf's distribution and type-token curves; point estimators, Maximum Likelihood estimation, bias and variance, sparseness, smoothing and clustering; interpolation, shrinkage, and backoff; entropy, cross entropy and mutual information;  decision tree models applied to language; latent variable models and the EM algorithm; hidden Markov models; exponential models and maximum entropy; semantic modeling and dimensionality reduction; probabilistic context-free grammars and syntactic language models.  The course is designed for LTI & SCS graduate students, but others are welcome.  CS UG upperclassmen who've taken it have done well, though they found it challenging.  The 11-661 version does not require the course project.  Prerequisites: Strong quantitative aptitude.  Comfort with basic UG-level probability.  Some programming skill.
LTI11663 | Applied Machine Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11663&SEMESTER=S15 | instructors:Rose, Carolyn description:Machine Learning is concerned with computer programs that enable the behavior of a computer to be learned from examples or experience rather than dictated through rules written by hand.  It has practical value in many application areas of computer science such as on-line communities and digital libraries.  This class is meant to teach the practical side of machine learning for applications, such as mining newsgroup data or building adaptive user interfaces.  The emphasis will be on learning the process of applying machine learning effectively to a variety of problems rather than emphasizing an understanding of the theory behind what makes machine learning work.  This course does not assume any prior exposure to machine learning theory or practice. In the first 2/3 of the course, we will cover a wide range of learning algorithms that can be applied to a variety of problems.  In particular, we will cover topics such as decision trees, rule based classification, support vector machines, Bayesian networks, and clustering. In the final third of the class, we will go into more depth on one application area, namely the application of machine learning to problems involving text processing, such as information retrieval or text categorization.
LTI11675 | Big Data Systems in Practice | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11675&SEMESTER=S15 | instructors:Starzl, Ravi description:To be determined
LTI11676 | Big Data AnalyticsThis Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11676&SEMESTER=F14 | instructors:Starzl, Ravi description:TBD
LTI11690 | MIIS Directed Study | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11690&SEMESTER=S15 | instructors:Frederking, Robert description:to be determined by the department
LTI11693 | Software Method for Biotechnology | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11693&SEMESTER=F14 | instructors:Starzl, Ravi description:Moore's law describes how processing power continues to be faster, better, and cheaper. It not only powered the computer industry forward, but it also is a key driver for propelling biotechnology. It is hard to imagine the world of biotechnology without the world of software. Moreover, the future will further underscore software's importance for enabling biotechnology innovations.   This course is focusing on the relationship between biotechnology processes and information technology where students will be introduced to business process workflow modeling and how these concepts are applied in large organizations. Through this method, students will learn the key drivers behind information systems and how to identify organizational opportunities and leverage these to create disruptive models. Student will also learn to assess new technology sectors for unsolved problems and commercially viable solutions   By taking this course, students will become conversant with the software technologies that can be applied to commercial life science problems in the present and future.
LTI11695 | Competitive Engineering | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11695&SEMESTER=S15 | instructors:Starzl, Ravi Vu, Du (John) description:In the second core course, students will be tasked with building a software application prototype for a biotech/pharmaceutical firm. Students will be introduced to a particular firm (through one of the program advisors) and will learn how to conduct and develop requirements analysis and convert that into feature definition. The customer requirements are often a moving target: they're influenced by the emergence of competitive alternatives (e.g. internal consultants, off-the-shelf software) and also by the team interaction with each others. Students will learn to create a product that best captures the best balance of the customer priorities and feasibility and distinguishing it from competitive alternatives. They will then use this learning to develop their respective prototypes. At the conclusion of the term, teams will compete with each other to determine which team's product is superior. In addition to having to apply various aspects of software development and computational learning, the course will help to provide students with some key insights into how biotech/pharmaceutical businesses operate.        In addition to concepts regarding market demand, students will learn how to aggregate and synthesize information related to demand, pricing and competition. They will then apply this learning to define and prioritize market driven requirements as it relates to a product. This information will then be used to build a product development plan. Students will utilize methods to enhance product quality and customer satisfaction: benchmarking; industry and customer analyses; project metrics, and a range of customer relationship management tools.
LTI11696 | MIIS Capstone Planning Seminar | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11696&SEMESTER=S15 | instructors:Nyberg, Eric description:The MIIS Capstone Planning Seminar prepares students to complete the MIIS Capstone Project in the following semester.  Students are organized into teams that will work together to complete the capstone project.  They define project goals, requirements, success metrics, and deliverables; and they identify and acquires data, software, and other resources required for successful completion of the project. The planning seminar must be completed in the semester prior to taking the capstone project.
LTI11699 | MSBIC Program Capstone | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11699&SEMESTER=S15 | instructors:Vu, Du (John) description:The final term will integrate all of the acquired learning in the program towards the development of a formal business plan and software product beta. The effort involved in the capstone project is quite intense and will consist of approximately three months of full time work for each student. The expected deliverables (features to be developed, business plan, technical documentation, etc.) must be agreed to by the course instructor at the outset of the course.    The capstone can either encompass the development of an industry sponsored software project or a software product intended for entrepreneurial startup. Students are expected to showcase their business and software projects and elicit feedback from academics, industry professionals, investors, and business executives. This phase also acts as an incubation period for companies that will be launched from the program.
LTI11700 | LTI Colloquium | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11700&SEMESTER=S15 | instructors:Lavie, Alon description:The LTI colloquium is a series of talks related to language technologies. The topics include but are not restricted to Computational Linguistics, Machine Translation, Speech Recognition and Synthesis, Information Retrieval, Computational Biology, Machine Learning, Text Mining, Knowledge Representation, Computer-Assisted Language Learning and Intelligent Language Tutoring. To get credit of the course, students are required to write either a short critique of one of the presentations or a comparison of two.
LTI11711 | Algorithms for NLP | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11711&SEMESTER=F14 | instructors:Lavie, Alon Dyer, Christopher Frederking, Robert description:Algorithms for NLP is an introductory graduate-level course on the computational properties of natural languages and the fundamental algorithms for processing natural languages. The course will provide an in-depth presentation of the major algorithms used in NLP, including Lexical, Morphological, Syntactic and Semantic analysis, with the primary focus on parsing algorithms and their analysis.
LTI11712 | Lab in NLP | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11712&SEMESTER=S15 | instructors:Lavie, Alon description:The Self-Paced Lab in NLP Algorithms is intended to complement the 11-711 lecture course by providing a chance for hands-on, in-depth exploration of various NLP paradigms. Students will study a set of on-line course materials and complete a set of programming assignments illustrating the concepts taught in the lecture course. Timing of individual assignments is left up to the student, although all assignments must be successfully completed and turned in before the end of the semester for the student to receive credit for the course.
LTI11713 | Advanced NLP Seminar | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11713&SEMESTER=F14 | instructors:Smith, Noah description:This course aims to improve participants' knowledge of current techniques, challenges, directions, and developments in all areas of NLP (i.e., across applications, symbolic formalisms, and approaches to the use of data and knowledge); to hone students' critical technical reading skills, oral presentation skills, and written communication skills; to generate discussion among students across research groups to inspire new research. In a typical semester, a set of readings will be selected (with student input) primarily from the past 2-3 years' conference proceedings (ACL and regional variants, EMNLP, and COLING), journals (CL, JNLE), and relevant collections and advanced texts. Earlier papers may be assigned as background reading. In 2010, the readings will primarily be recent dissertations in NLP. The format of each meeting will include a forty-minute, informal, critical student presentation on the week's readings, with presentations rotating among participants, followed by general discussion. Apart from the presentation and classroom participation, each student will individually write a 3-4-page white paper outlining a research proposal for new work extending research discussed in class - this is similar to the Advanced IR Seminar.
LTI11714 | Tools for NLP | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11714&SEMESTER=F14 | instructors:Hovy, Eduard description:This course is designed as a hands-on lab to help students interested in NLP build their own compendium of the open-source tools and resources available online.  Ideally taken in the first semester, the course focuses on one basic topic every two weeks, during which each student will download, install, and play with two or three packages, tools, or resources, and compare notes.  The end-of-semester assignment will be to compose some of the tools into a system that does something interesting.  We will cover a range, from the most basic tools for sentence splitting and punctuation removal through resources such as WordNet and the Penn Treebank to parsing and Information Extraction engines.
LTI11716 | Graduate Seminar on Dialog Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11716&SEMESTER=F14 | instructors:Rudnicky, Alex description:Dialog systems and processes are becoming an increasingly vital area of interest both in research and in practical applications. The purpose of this course will be to examine, in a structured way, the literature in this area as well as learn about ongoing work.  The course will cover traditional approaches to the problem, as exemplified by the work of Grosz and Sidner, as well as more recent work in dialog, discourse and evaluation, including statistical approaches to problems in the field. We will select several papers on a particular topic to read each week. While everyone will do all readings, a presenter will be assigned to overview the paper and lead the discussion. On occasion, a researcher may be invited to present their own work in detail and discuss it with the group. A student or researcher taking part in the seminar will come away with a solid knowledge of classic work on dialog, as well as familiarity with ongoing trends.
LTI11719 | Computational Models of Discourse Analysis | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11719&SEMESTER=S15 | instructors:Rose, Carolyn description:Discourse analysis is the area of linguistics that focuses on the structure of language above the clause level.  It is interesting both in the complexity of structures that operate at that level and in the insights it offers about how personality, relationships, and community identification are revealed through patterns of language use.  A resurgence of interest in topics related to modeling language at the discourse level is in evidence at recent language technologies conferences.  This course is designed to help students get up to speed with foundational linguistic work in the area of discourse analysis, and to use these concepts to challenge the state-of-the-art in language technologies for problems that have a strong connection with those concepts, such as dialogue act tagging, sentiment analysis, and bias detection.  This is meant to be a hands on and intensely interactive course with a heavy programming component.  The course is structured around 3 week units, all but the first of which have a substantial programming assignment structured as a competition (although grades will not be assigned based on ranking within the competition, rather grades will be assigned based on demonstrated comprehension of course materials and methodology).
LTI11721 | Grammars and Lexicons | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11721&SEMESTER=F14 | instructors:Levin, Lorraine Mitamura, Teruko description:Grammars and Lexicons is an introductory graduate course on linguistic data analysis and theory, focusing on methodologies that are suitable for computational implementations. The course covers major syntactic and morphological phenomena in a variety of languages. The emphasis will be on examining both the diversity of linguistic structures and the constraints on variation across languages. Students will be expected to develop and defend analyses of data, capturing linguistic generalizations and making correct predictions within and across languages. The goal is for students to become familiar with the range of phenomena that occur in human languages so that they can generalize the insights into the design of computational systems. The theoretical framework for syntactic and lexical analysis will be Lexical Functional Grammar. Grades will be based on problem sets and take-home exams.
LTI11723 | Linguistics Lab | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11723&SEMESTER=S15 | instructors:Levin, Lorraine description:Formal Semantics is an introductory graduate course on formal linguistic semantics: Given a syntactic analysis of a natural language utterance, how can one assign the correct meaning representation to it, using a formal logical system? More details TBA.
LTI11726 | Meaning in Language Lab (Self Paced) | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11726&SEMESTER=S15 | instructors:Rose, Carolyn description:The self-paced Meaning in Language Lab is intended to follow-up on the 11-725 lecture course (Meaning in Language) by providing a chance for hands-on, in-depth, computational exploration of various semantics and pragmatics research topics. The course is self-paced and there will be no scheduled lecture times, however, students are welcome to set up meetings with the instructor as desired, and students who prefer to have a weekly or bi-monthly regularly scheduled meeting with the instructor are welcome to arrange for that. If there is sufficient interest, an informal reading group may be formed to supplement the lab work.    Students will design their own project, which they will discuss with the instructor for approval. Students are encouraged to select a topic from semantics, pragmatics, or discourse analysis, such as entailment, evidentiality, implicature, information status, or rhetorical structure, and a topic from language technologies, such as sentiment analysis or summarization, and explore how the linguistic topic applies to some aspect of the chosen language technology. Students are encouraged to contrast symbolic, formal, and knowledge based approaches with empirical approaches.    Each student will work independently. If multiple students work as a team on a particular topic, each should choose an approach that is different from the approaches used by the other students working on the same problem. Students will be responsible to set up a web page, blog, or wiki to post progress reports and other supporting documents, data, and analyses. The web space will be checked by the instructor periodically , and thus should be kept updated in order to reflect on-going progress. The web space will also serve as a shared project space in the case that students are working in a team for the project.
LTI11727 | Computational Semantics for NLP | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11727&SEMESTER=S15 | instructors:Hovy, Eduard Mitamura, Teruko description:This course surveys semantics from a language processing perspective.  It is divided into three main sections supplemented with a substantive semester-long computational project.  The first section addresses traditional topics of computational semantics and semantic processing and representation systems.  The second focuses on computational lexical semantics, including resources such as WordNet, Framenet, and some word-based ontologies, and their computational applications, such as word sense disambiguation, entailment, etc., and briefly the semantic web.  The third section covers modern statistics-based distributional models of semantics.  Each week focuses on one topic, covered by the lecturers, and will include one or two core introductory readings plus several optional more advanced readings.  All students will read and discuss the introductory readings while each student will be expected to read advanced papers on at least two topics.
LTI11728 | Advanced Seminar in SemanticsThis Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11728&SEMESTER=S15 | instructors:Mitamura, Teruko Hovy, Eduard description:This course is an introductory survey of computational semantics from a language processing perspective. The first section is devoted to traditional topics of computational semantics and semantic processing and representation systems.  The second focuses on lexical semantics, including resources such as WordNet, Framenet, and some word-based ontologies.  In the third month we consider computational applications of semantics, such as word sense disambiguation, entailment, etc., and also look at the semantic web.  The fourth month ends with modern statistics-based distributional models of semantics.  Each week, we cover one topic, which will be introduced by the faculty and will include one or more appropriate readings that will be reviewed by students and discussed in class.  This is a 6-unit reading seminar that meets once a week.
LTI11729 | Semantics Lab | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11729&SEMESTER=F14 | instructors:Mitamura, Teruko Hovy, Eduard description:TBD
LTI11731 | Machine Translation | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11731&SEMESTER=S15 | instructors:Dyer, Christopher Lavie, Alon description:Instructors: Chris Dyer (leader), Alon Lavie.  Prerequisites: 11-711 "Algorithms for NLP" or equivalent background is recommended. Course   Machine Translation is an introductory graduate-level course surveying the primary approaches and methods for developing modern state-of-the-art automated language translation systems.  The main objectives of the course are: Obtain a basic understanding of modern MT systems and MT-related issues. Learn about theory and approaches in Machine Translation and implement the main components of statistical MT systems.
LTI11732 | Self-Paced Lab: MT | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11732&SEMESTER=F14 | instructors:Dyer, Christopher Lavie, Alon prereq:11731 description:The Self-Paced Lab in MT is intended to complement the 11-731 lecture course by providing a chance for hands-on, in-depth exploration of various MT paradigms. MT faculty will present a set of possible topics to the students enrolled in the course. The students will indicate their first and second choices for lab projects, and will then be matched to a lab project advisor. At the end of the semester, the students will present the results of their projects in class, and submit a short paper describing them.
LTI11733 | Multilingual Speech-to-Speech Translation Lab | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11733&SEMESTER=F14 | instructors:Black, Alan description:Building speech-to-speech translation systems (S-2-S) is an extremely complex task, involving research in Automatic Speech Recognition (ASR), Machine Translation (MT), Natural Language Understanding (NLU), as well as Text-to-Speech (TTS) and doing this for many languages doesn't make it easier. Although substantial progress has been made in each of these areas over the last years, the integration of the invididual ASR, MT, NLU, and TTS components to build a good S-2-S system is still a very challenging task.    The seminar course on Multilingual Speech-to-Speech Translation will cover important recent work in the areas of ASR, MT, NLU, and TTS with a special focus on language portable approaches and discuss solutions for rapidly building state-of-the-art speech-to-speech translation systems.    In the beginning sessions the instructors and other invited lecturers will give a brief introduction into the broad field. We will select papers on particular topics to read by each week. While everyone will do all readings and participate in the discussions, one person is assigned per session to present the basic ideas of the topic specific papers and lead the concluding discussion.
LTI11734 | Advanced Machine Translation SeminarThis Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11734&SEMESTER=S15 | instructors:Lavie, Alon Dyer, Christopher prereq:11731 description:The Advanced Machine Translation Seminar is a graduate-level seminar on current research topics in Machine Translation. The seminar will cover recent research on different approaches to Machine Translation (Statistical MT, Example-based MT, Interlingua and rule-based approaches, hybrid approaches, etc.). Related problems that are common to many of the various approaches will also be discussed, including the acquisition and construction of language resources for MT (translation lexicons, language models, etc.), methods for building large sentence-aligned bilingual corpora, automatic word alignment of sentence-parallel data, etc. The material covered will be mostly drawn from recent conference and journal publications on the topics of interest and will vary from year to year. The course will be run in a seminar format, where the students prepare presentations of selected research papers and lead in class discussion about the presented papers.   Prerequisites & corequisites:     11-731: Machine Translation, or instructor approval.
LTI11736 | Graduate Seminar on Endangered Languages | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11736&SEMESTER=F14 | instructors:Black, Alan Frederking, Robert Levin, Lorraine Tomokiyo, Laura description:The purpose of this seminar is to allow students to better understand the linguistic, social and political issues when working with language technologies for endangered languages. Often in LTI we concentrate on issues of modeling with small amounts of data, or designing optimal strategies for collecting data, but ignore many of wider practical issues that appear when working with endangered languages.     This seminar will consist of reading books and papers, and having participants give presentations; a few invited talks (e.g. from field linguists, and language advocates) will also be included. It will count for 6 units of LTI course credit. It may be possible for interested students to also carry out a related 6-unit project as a lab.
LTI11741 | Machine Learning for Text Mining | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11741&SEMESTER=S15 | instructors:Yang, Yiming description:This course studies the theory, design, and implementation of text-based information systems. The Information Retrieval core components of the course include statistical characteristics of text, representation of information needs and documents, several important retrieval models (Boolean, vector space, probabilistic, inference net, language modeling), clustering algorithms, automatic text categorization, and experimental evaluation. The software architecture components include design and implementation of high-capacity text retrieval and text filtering systems. A variety of current research topics are also covered, including cross-lingual retrieval, document summarization, machine learning, topic detection and tracking, and multi-media retrieval.      Prerequisites:      Programming and data-structures at the level of 15-212 or higher.  Algorithms comparable to the undergraduate CS algorithms course (15-451) or higher.  Basic linear algebra (21-241 or 21-341).   Basic statistics (36-202) or higher.
LTI11742 | Self-paced Lab: IR | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11742&SEMESTER=F14 | instructors:Callan, James Yang, Yiming description:The Self-Paced Lab for Information Retrieval (IR Lab) is intended to complement the 11-741 lecture course (IR Core) by providing a chance for hands-on, in-depth exploration of various IR research topics. Students will design their own projects (project examples) and discuss instructor for approval. Each student will work independently. If multiple students work as a team on a particular topic, each should choose an approach that is different from the approaches used by the other students working on the same problem. Make a Web page for progress report and communication. Your Web page will be checked by the instructor periodically thus should be updated timely to reflect your on-going progress and work organization. The Web pages will also serve a role of data/tools sharing among students.
LTI11743 | Self-Paced Lab: IR | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11743&SEMESTER=S15 | instructors:Yang, Yiming prereq:11741 or 15886 description:Advanced Information Retrieval Seminar and Lab is a seminar that focuses on current research in Information Retrieval. The seminar covers recent research on subjects such as retrieval models, text classification, information gathering, fact extraction, information visualization, summarization, text data mining, information filtering, collaborative filtering, question answering systems, and portable information systems. Other topics are drawn from recent SIGIR, Digital Libraries, TREC, Machine Learning, and AAAI conferences. Course content varies from year to year.  Students not taking the course for credit are welcome to audit or sit in on the course, subject to availability of space.
LTI11745 | Advanced Statistical Learning Seminar | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11745&SEMESTER=S15 | instructors:Yang, Yiming description:This seminar aims to deepen the participants' understanding of the theoretical foundation of statistical learning and applications, to broaden their knowledge of new techniques, directions and challenges in the field, and to inspire research ideas through class-room discussions.  In the past years, this seminar was structured as a 12-unit course in the form of group-reading, presenting and discussing the book (chapter by chapter) of The Elements of Statistical Learning: Data Mining, Inference, and Prediction by Trevor Hastie et al. In the fall of 2014, we will have a 6-unit seminar, focusing on New Methods in Large-scale Structured Learning, with selected papers from the past 2-3 years of ICML, NIPS, KDD, JMLR or the like, plus related background reading. We will meet once a week, one topic per week (1-2 papers), with presentations rotating among participants. In each week, the assigned presenter starts with the questions from all the participants (collected by email) about the current topic, followed by a presentation on that topic and leads the discussion. All the students are required to read the assigned paper(s) of the week before the class, and email their questions to the presenter (CC to everybody). By the end of the semester, each student will individually write a short 3-4-page white paper outlining a research proposal for new work extending one of the research areas discussed in class.  There will be no exams or homework; the grading is based on class participation, quality of the seminar presentation(s), questions submitted for each class and discussions, and the final brief paper. Prerequisites: Intro machine learning and related courses
LTI11751 | Speech Recognition and Understanding | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11751&SEMESTER=F14 | instructors:Metze, Florian description:The technology to allow humans to communicate by speech with machines or by which machines can understand when humans communicate with each other is rapidly maturing. This course provides an introduction to the theoretical tools as well as the experimental practice that has made the field what it is today. We will cover theoretical foundations, essential algorithms, major approaches, experimental strategies and current state-of-the-art systems and will introduce the participants to ongoing work in representation, algorithms and interface design. This course is suitable for graduate students with some background in computer science and electrical engineering, as well as for advanced undergraduates. Prerequisites: Sound mathematical background, knowledge of basic statistics, good computing skills. No prior experience with speech recognition is necessary. This course is primarily for graduate students in LTI, CS, Robotics, ECE, Psychology, or Computational Linguistics. Others by prior permission of instructor.
LTI11752 | Speech II: Phonetics, Prosody, Perception and SynthesisThis Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11752&SEMESTER=S15 | instructors:Eskenazi, Maxine Black, Alan description:The goal of the course is to give the student basic knowledge from several fields that is necessary in order to pursue research in automatic speech processing. The course will begin with a study of the acoustic content of the speech signal. The students will use the spectrographic display to examine the signal and discover its variable properties. Phones in increasingly larger contexts will be studied with the goal of understanding coarticulation. Phonological rules will be studied as a contextual aid in understanding the spectrographic display. The spectrogram will then serve as a first introduction to the basic elements of prosody. Other displays will then be used to study the three parts of prosody: amplitude, duration, and pitch. Building on these three elements, the student will then examine how the three interact in careful and spontaneous speech.     Next, the students will explore perception. Topics covered will be:   physical aspects of perception, psychological aspects of perception, testing perception processes, practical applications of knowledge about perception.   The second part of this course will cover all aspects of speech synthesis.     Students need only have a basic knoweldge of speech and language processing. Some degree of programming and statistical modelling will be beneficial, but not required.    Taught every other year
LTI11753 | Advanced Laboratory in Speech Recognition | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11753&SEMESTER=S15 | instructors:Metze, Florian description:The technology to allow humans to communicate by speech with machines or by which machines can understand when humans communicate with each other is rapidly maturing. While the 11-751 speech course focussed on an introduction to the theoretical foundations, essential algorithms, major approaches, and strategies for current state-of-the-art systems, the 11-753 speech lab complements the education by concentrating on the experimental practice in developing speech recognition and understanding speech-based systems, and by getting hands-on experience on relevant research questions using state-of-the art tools. Possible problem sets include both core speech recognition technology, and the integration of speech-based components into multi-modal, semantic, learning, or otherwise complex systems and interfaces.
LTI11754 | Project Course: Dialogue Systems | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11754&SEMESTER=S15 | instructors:Black, Alan Rudnicky, Alex description:This course will teach participants how to implement a complete spoken language system while providing opportunities to explore research topics of interest in the context of a functioning system. The course will produce a complete implementation of a system to access and manipulate email through voice only, for example to allow users to interact with the mail system over a telephone while away from their computer. In doing so the class will address the component activities of spoken language system building. These include, but are not limited to, task analysis and language design, application-specific acoustic and language modeling, grammar design, task design, dialog management, language generation and synthesis. The course will place particular emphasis on issues in task design and dialog management and on issues in language generation and synthesis.     For Fall, we will implement a simple telephone-based information access application. The domain is bus schedules (see http://www.speech.cs.cmu.edu/BusLine for a web-based interface to this domain) and the goal will be to create one or more usable applications that can provide a real service and can be deployed for actual use by the University community. Participants will chose individual components of the system to concentrate on and will collaborate to put together the entire system. It is perfectly acceptable for several individuals to concentrate on a single component, particularly if their work will exemplify alternative approaches to the same problem.
LTI11755 | Machine Learning for Signal Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11755&SEMESTER=S15 | instructors:Ramakrishnan, Bhiksha description:Signal Processing is the science that deals with extraction of information from signals of various kinds. This has two distinct aspects -- characterization and categorization. Traditionally, signal characterization has been performed with mathematically-driven transforms, while categorization and classification are achieved using statistical tools.     Machine learning aims to design algorithms that learn about the state of the world directly from data.     A increasingly popular trend has been to develop and apply machine learning techniques to both aspects of signal processing, often blurring the distinction between the two.     This course discusses the use of machine learning techniques to process signals. We cover a variety of topics, from data driven approaches for characterization of signals such as audio including speech, images and video, and machine learning methods for a variety of speech and image processing problems.
LTI11756 | Design and Implementation of Speech Recognition Systems | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11756&SEMESTER=S15 | instructors:Ramakrishnan, Bhiksha description:Voice recognition systems invoke concepts from a variety of fields including speech production, algebra, probability and statistics, information theory, linguistics, and various aspects of computer science. Voice recognition has therefore largely been viewed as an advanced science, typically meant for students and researchers who possess the requisite background and motivation.  In this course we take an alternative approach. We present voice recognition systems through the perspective of a novice. Beginning from the very simple problem of matching two strings, we present the algorithms and techniques as a series of intuitive and logical increments, until we arrive at a fully functional continuous speech recognition system.  Following the philosophy that the best way to understand a topic is to work on it, the course will be project oriented, combining formal lectures with required hands-on work. Students will be required to work on a series of projects of increasing complexity. Each project will build on the previous project, such that the incremental complexity of projects will be minimal and eminently doable. At the end of the course, merely by completing the series of projects students would have built their own fully-functional speech recognition systems.  Grading will be based on project completion and presentation.
LTI11757 | Advanced Topics: Statistical Modeling for Spoken Dialog Systems | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11757&SEMESTER=F14 | instructors:Eskenazi, Maxine Lee, Sungjin description:None
LTI11761 | Language and Statistics | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11761&SEMESTER=S15 | instructors:Rosenfeld, Ronald description:Language technologies (search, text mining, information retrieval, speech recognition, machine translation, question answering, biological sequence analysis...) are at the forefront of this century's information revolution.  In addition to their use of machine learning, these technologies rely centrally on classic statistical estimation techniques.   Yet most CS and engineering undergraduate programs do not prepare students in this area beyond an introductory prob&stats course.  This course is designed to plug this hole.  The goal of "Language and Statistics" is to ground the data-driven techniques used in language technologies in sound statistical methodology.   We start by formulating various language technology problems in both an information theoretic framework (the source-channel paradigm) and a Bayesian framework (the Bayes classifier).  We then discuss the statistical properties of words, sentences, documents and whole languages, and the computational formalisms used to represent language.  These discussions naturally lead to specific concepts in statistical estimation.  Topics include: Zipf's distribution and type-token curves; point estimators, Maximum Likelihood estimation, bias and variance, sparseness, smoothing and clustering; interpolation, shrinkage, and backoff; entropy, cross entropy and mutual information;  decision tree models applied to language; latent variable models and the EM algorithm; hidden Markov models; exponential models and maximum entropy; semantic modeling and dimensionality reduction; probabilistic context-free grammars and syntactic language models.  The course is designed for LTI & SCS graduate students, but others are welcome.  CS UG upperclassmen who've taken it have done well, though they found it challenging.  The 11-661 version does not require the course project.  Prerequisites: Strong quantitative aptitude.  Comfort with basic UG-level probability.  Some programming skill.
LTI11775 | Large-Scale Multi-media Analysis | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11775&SEMESTER=S15 | instructors:Hauptmann, Alexander Metze, Florian description:TBA
LTI11782 | Self-Paced Lab for Computational Biology | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11782&SEMESTER=S15 | instructors:Xing, Poe prereq:10810 description:Students will choose from a set of projects designed by the instructor. Students will also have the option of designing their own projects, subject to instructor approval. For the students who had completed a project in the 10-810 course, they can either switch to another project, or continue working on the previous project by aiming a significant progress (subject to instructor approval). Each student will work independently. If more than one student work on a particular topic, each should choose an approach that is different from the approaches used by the other students working on the same problem. The students need to begin with a project proposal to outline the high-level ideas, tasks, and goals of the problem, and plan of experiments and/or analysis. The instructor will consult with you on your ideas , but the final responsibility to define and execute an interesting piece of work is yours. Your project will have two final deliverables: 1. a writeup in the form of a NIPS paper (8 pages maximum in NIPS format, including references), worth 60% of the project grade, and 2. a research seminar presentation of your work at the end of the semester, worth 20% of the project grade. In addition, you must turn in a midway progress report (5 pages maximum in NIPS format, including references) describing the results of your first experiments, worth 20% of the project grade. Note that, as with any conference, the page limits are strict! Papers over the limit will not be considered. The grading of your project are based on overall scientific quality, novelty, writing, and clarity of presentation. We expect your final report to be of conference-paper quality, and you are expected to also deliver software implementation of your algorithmic results.
LTI11783 | Self-Paced Lab: Rich Interaction in Virtual World | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11783&SEMESTER=S15 | instructors:Metze, Florian prereq:11751 and 18781 and 18799 description:Massively Multi-player Online Role-Playing Games have evolved into Virtual Worlds (VWs), and are creating ever richer environments for experimentation on all aspects of human to human, or human to machine communication, as well as for information discovery and access. So far, interaction has been constrained by the limited capabilities of keyboards, joysticks, or computer mice. This creates an exciting opportunity for explorative research on speech input and output, speech-to-speech translation, or any aspect of language technology. Of particular interest will be a combination with other novel "real world" (RW) input, or output devices, such as mobile phones or portable games consoles, because they can be used to control the VW, or make it accessible everywhere in RW. Language technologies in particular profit from "context awareness", because domain adaptation can be performed. For scientific experimentation in that area, Virtual Worlds offer the opportunity to concentrate on algorithms, because context sensors can be written with a few lines of code, without the need for extra hardware sensors. Algorithms can also run "continuously", without the need for specific data collection times or places, because the VW is "always on".    In this lab, we will enhance existing clients to virtual worlds so that they can connect to various speech and language related research systems developed at LTI and CMU's Silicon Valley campus. The lab will be held jointly at the CMU's Pittsburgh and Silicon Valley Campuses. We will "eat our own dog food", so the goal will be to hold the last session entirely in a virtual class room, which will by that time include speech control of virtual equipment, speech-to-speech translation, and some devices that can be controlled using non-PC type equipment, like mobile phones. Eventually, this virtual room or the know-how gathered
LTI11785 | Lab Course on Deep Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11785&SEMESTER=F14 | instructors:Ramakrishnan, Bhiksha description:to be determined by department
LTI11791 | Design &amp; Engineering of Intelligent Information Systems | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11791&SEMESTER=F14 | instructors:Nyberg, Eric description:The Software Engineering for IT sequence combines classroom material and assignments in the fundamentals of software engineering (11-791) with a self-paced, faculty-supervised directed project (11-792). The two courses cover all elements of project design, implementation, evaluation, and documentation.    For students intending to complete both courses, it is recommended that the project design and proof-of-concept prototype be completed and approved by the faculty advisor before the start of 11-792, if possible. Students may elect to take only 11-791; however, if both parts are taken, they should be taken in proper sequence.
LTI11792 | Intelligent Information Systems Project | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11792&SEMESTER=S15 | instructors:Nyberg, Eric prereq:11791 or 15393 description:The Software Engineering for IS sequence combines classroom material and assignments in the fundamentals of software engineering (11-791) with a self-paced, faculty-supervised directed project (11-792). The two courses cover all elements of project design, implementation, evaluation, and  documentation. Students may elect to take only 11-791; however, if both parts are taken, they should be taken in proper sequence. Prerequisite: 11-791. The course is required for VLIS students.
LTI11796 | Question Answering Lab | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11796&SEMESTER=S15 | instructors:Mitamura, Teruko Nyberg, Eric prereq:11791 description:The Question Answering Lab provides a hands-on introduction to existing approaches to question answering (QA). Students will define their own project, with approval from the instructor. Each student will work independently. If multiple students work as a team on a particular topic, each should choose an approach that is different from the approaches used by the other students working on the same problem. Students will document their approach and progress on a wiki page that is shared with the instructor. Grading will be based on periodic and final review of the student progress as documented on the wiki.
LTI11797 | Question Answering | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11797&SEMESTER=S15 | instructors:Nyberg, Eric Mitamura, Teruko description:The Question Answering course provides a chance for hands-on, in-depth exploration of core algorithmic approaches to question answering (QA). Students will work independently or in small teams to extend or adapt existing QA modules and systems to improve overall performance on known QA datasets (e.g. TREC, CLEF, NTCIR), using best practices associated with the Open Advancement of Question Answering initiative. Each student project will evaluate one or more component algorithms on a given QA dataset and produce a conference-style paper describing the system design, experimental setup and results.
LTI11805 | Machine Learning with Large Datasets | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11805&SEMESTER=S15 | instructors:Cohen, William description:Large datasets are difficult to work with for several reasons. They are difficult to visualize, and it is difficult to understand what sort of errors and biases are present in them. They are computationally expensive to process, and often the cost of learning is hard to predict - for instance, and algorithm that runs quickly in a dataset that fits in memory may be exorbitantly expensive when the dataset is too large for memory. Large datasets may also display qualitatively different behavior in terms of which learning methods produce the most accurate predictions.This course is intended to provide a student practical knowledge of, and experience with, the issues involving large datasets. Among the issues considered are: scalable learning techniques, such as streaming machine learning techniques; parallel infrastructures such as map-reduce; practical techniques for reducing the memory requirements for learning methods, such as feature hashing and Bloom filters; and techniques for analysis of programs in terms of memory, disk usage, and (for parallel methods) communication complexity.
LTI11821 | Advanced Linguistics Seminar | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11821&SEMESTER=S15 | instructors:Levin, Lorraine description:None
LTI11823 | ConLanging: Lrng. Ling. &amp; Lang Tech via Constru Artif. Lang. | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11823&SEMESTER=S15 | instructors:Black, Alan Levin, Lorraine description:TBD
LTI11899 | Summarization of Documents and Interaction | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11899&SEMESTER=F14 | instructors:Rose, Carolyn description:The problem of information overload in personal communication media such as email, instant messaging, and on-line forums is a well documented phenomenon. Much work addressing this problem has been conducted separately in the human-computer interaction (HCI) community, the information sciences community, and the computational linguistics community.  However, in each case, while important advancements in scientific knowledge have been achieved, the work suffers from an "elephant complex", where each community focuses mainly on just the part of the problem most visible from their own perspective.  The purpose of this course is to bring these threads together to examine the issue of managing personal communication data from an integrated perspective.
LTI11910 | Directed Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11910&SEMESTER=M15 | description:This course number documents the research being done by Masters and pre-proposal PhD students. Beginning in Fall 2001, every LTI graduate student will register for at least 24 units of 11-910 each semester, unless they are ABD (i.e., they have had a thesis proposal accepted), in which case they should register for 48 units of 11-930. The student will be expected to write a report and give a presentation at the end of the semester, documenting the research done. The report will be filed by either the faculty member or the LTI graduate program administrator.   (Until Fall 2001 this course number was used for individual study in connection with LTI project research work and was a Pass/Fail course.)
LTI11920 | Independent Study: Breadth | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11920&SEMESTER=M15 | instructors:Frederking, Robert description:This course number is intended for individual study with faculty other than a student's intended thesis advisor.
LTI11925 | Independent Study: Area | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11925&SEMESTER=M15 | description:This course number is intended for individual study with the intended thesis advisor prior to acceptance of a student's thesis proposal.
LTI11927 | MIIS Capstone Project | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11927&SEMESTER=M15 | description:The capstone project course is a group-oriented demonstration of student skill in one or more areas covered by the degree. Typically the result of the capstone project is a major software application. The capstone project course consists of two components.  The classroom component guides students in project planning, team management, development of requirements and design specifications, and software tools for managing group-oriented projects.  The lab component provides project-specific technical guidance and expertise, for example in the development of a question answering system, dialog, or sentiment analysis application.  Thus, each project receives two types of supervision, often from two separate members of the faculty.
LTI11928 | Masters Thesis I | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11928&SEMESTER=F14 | instructors:Frederking, Robert description:This course number is intended for last semester Masters students who wish to do an optional Masters Thesis.
LTI11929 | Masters Thesis II | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11929&SEMESTER=S15 | instructors:Frederking, Robert description:This course number is intended for last semester Masters students who wish to do an optional Masters Thesis. The student will normally have taken 11-925 Independent Study: Area of Concentration for 12 units in the preceding semester, to produce an MS Thesis Proposal.
LTI11930 | Dissertation Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11930&SEMESTER=M15 | description:This course number is intended for PhD dissertation research after acceptance of a student's PhD thesis proposal.
LTI11935 | LTI Practicum | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11935&SEMESTER=M15 | instructors:Frederking, Robert description:This course is intended as an internship course for students who are doing Curricular Practical Training (CPT) as part of their graduate degree.
