mit-media-viral-communications-1 | Crystal Ball | http://viral.media.mit.edu/projects/crystalball/ | description:Amir Lazarovich, Dan Novy, Andy Lippman, Michael Bove A physical interface designed for simultaneous social interaction with visual material. We built a hemispherical, multi-person, interactive touch display that allows a small group of people in the same place or in equivalently equipped ones to jointly interact on the same surface. We created an application that runs on this platform and presents a selection of visual media and offers recommendations for common viewing. view site
mit-media-viral-communications-2 | Ethos | http://pvtcoin.org | description:Collaboration as part of the MIT Bitcoin contest: Oz Nathan, Guy Zyskind, and Amir Lazarovich Ethos is a decentralized, Bitcoin-like network for storing and sharing valuable information. We provide transparency, control, and ownership over personal data and its distribution. Validation and maintenance is distributed throughout the data community and automatically maintained without needing a safe deposit box or a commercial site. What Bitcoin has done for currency and BitTorrent for media, Ethos does for personal data. Nodes in the network are incentivized by collecting transaction fees, coinbase transactions ("finding blocks"), and proof-of-storage fees to sustain the distribution of personal data. Fees are paid with the underlying cryptocurrency represented by the network, also known as "PrivacyCoin." The role of nodes, besides the usual proof-of-work, which protects against "double spending," is to maintain shredded pieces of information and present them to the network on-demand. view site
mit-media-viral-communications-3 | GIFGIF | http://gifgif.media.mit.edu | description:Cesar A. Hidalgo, Andrew Lippman, Kevin Zeng Hu and Travis Rich An animated GIF is a magical thing. It has the power to compactly convey emotion, empathy, and context in a subtle way that text or emoticons often miss. GIFGIF is a project to combine that magic with quantitative methods. Our goal is to create a tool that lets people explore the world of GIFs by the emotions they evoke, rather than by manually entered tags. A web site with 200,000 users maps the GIFs to an emotion space and lets you peruse them interactively. view site
mit-media-viral-communications-4 | Glance | http://viral.media.mit.edu/projects/glance/ | description:Andrew Lippman and Vivian Diep We address two critical elements of news: that it informs, and that it is trustworthy. Glance creates dynamic, real-time, semantic control over news presentation that reveals the inherent slant that underlies coverage of an event. The goal is to empower readers to understand their news intake through a visualization of metadata that empowers readers to choose their news source based on computed metrics rather than sensationalized headlines. Relevant additional information, such as sentiment of text and public reaction, is gathered on each topic to further give readers a richer news-scape. view site
mit-media-viral-communications-5 | Glue | http://viral.media.mit.edu/projects/glue/ | description:Robert Hemsley, Jonathan Speiser, Dan Sawada, Savannah Niles, Eric Dahlseng, and Andrew Lippman Glue is a prototyping engine to support news and narrative analysis. The system works by coordinating the flow of media among an extensible set of asynchronous Python processing modules. The growing set of existing modules analyzes web pages, video, and exogenous data such as tweets and creates fine-grained metadata, including frame-by-frame analysis for video. We use this to organize material for presentation, analysis, and summarization. Currently, the system provides named-entity extraction, audio expression markers, face detectors, scene/edit point locators, excitement trackers, and thumbnail summarization. Glue includes a video recorder and processes 14 DirecTV feeds as well as video content crawled from the web. Video is retained dependent on storage capacity and the database is permanent. Glue is the metadata driver for most Ultimate Media projects—a “digestion system” for mass media. view site
mit-media-viral-communications-6 | Glyph | https://www.google.com.hk/?gws_rd=cr,ssl#safe=strict&q=mit-media-viral-communications-6 Glyph | description:Andrew Lippman and Savannah L Niles Wearable devices and ambient displays need to atomize video to evocative excerpts as glanceable as a still image. Glyph is a web-based tool for generating expressive GIFs from video. The tool integrates scene detection, video stabilization, video manipulation, and loop detection into a simple, web-based authoring interface. Glyph allows for creating GIFs from video with more editorial control than just choosing a clip's start and end time—diminishing some regions of movement in the clip, and highlighting others; erasing a jarring jump between the start and end of the GIF; imbuing a still image with just enough dynamism to hold our eyes and pique our interest. The result is a subtle, dynamic moving image that's lightweight, transmissible, and immediately engaging.
mit-media-viral-communications-7 | Helios | https://www.google.com.hk/?gws_rd=cr,ssl#safe=strict&q=mit-media-viral-communications-7 Helios | description:Eric Dahlseng Helios provides an automatic way of socializing one's video interactions. It is a Chrome browser plug-in that records user's encounters with embedded videos on the web. This data is contributed to a group collection so that one can readily see what is trending among friends and where the outliers are. In addition the data is processed by Glue for metadata tagging.
mit-media-viral-communications-8 | Invisible Ink | http://block.media.mit.edu | description:Amir Lazarovich, Andrew Lippman Invisible Ink is a certified mail application that demonstrates the utility of the blockchain for maintaining a public ledger of transactions while keeping the content of those transactions private. In this case, the idea is a method for guaranteeing the delivery, receipt and existence of email messages. It archives the transaction in the Bitcoin blockchain and uses secure off-chain storage for the other details. Invisible Ink demonstrates the extensibility of this distributed technology for contracts, audits, and recovery of sensitive information. It is an evolution of work begun as the Ethos project. Since Bitcoin has shown that a distributed system of trust can be workable for irreversibly storing time-stamped, information, these extensions and applications are potentially important for a wide variety of cases from finance to personal information. view site
mit-media-viral-communications-9 | Me.TV | http://viral.media.mit.edu/projects/learning_media/ | description:Andrew Lippman and Vivian Diep Me.TV is an exploration into programming that can automatically, personally, and extensibly build everything from a newspaper into an evening's entertainment. The programming is graphical, akin to Scratch, and consists of organizing ideas and formats that are analyzed as they are created. The language operates by position blocks that select, test, loop, and interrogate friends as well as intrinsic data to present an ever-varying, personalized, and communicated window into events and entertainment. This interface teaches analytical thinking while applying it to content. It replaces the tag-based search paradigm with a real-time interaction that hones the user's analytic skills while it builds a personal and sharable information resource. view site
mit-media-viral-communications-10 | NanoVideo | http://glyph.media.mit.edu/splintered_screens | description:Andrew Lippman and Savannah L Niles High-bandwidth media is no longer tethered to televisions and computers, as pixels increasingly occupy our peripheries—via mobile devices, wearables, and ambient displays. NanoVideo is a series of small, screen-equipped objects that demonstrates how images created by the tool Glyph can integrate video subtly, meaningfully, and socially into the background of our working and living environments. NanoVideo thus explores opportunities for designing new objects with new affordances that are integrated with and responsive to high-bandwidth visual media. view site
mit-media-viral-communications-11 | NewsClouds | http://viral.media.mit.edu/projects/newsclouds | description:Andrew Lippman and Thariq Shihipar Here we tackle the problem of social information overload. We call it the "Kish Problem" after a colleague who articulated it: people want to know everything, but presenting everything in real time is a meaningless blur—a signal to noise problem. Here we present a simple graphical aid for separating reportage from rumor, the tweets from the roots, and a way to explore who is saying what. NewsClouds uses the Glue engine to parse web and video and organizes it by source, emphasizing the exclusive of the two. NewsClouds allows interactive exploration of how topics evolve and migrate between diverse media. view site
mit-media-viral-communications-12 | QUANTIFY | http://quantify.media.mit.edu | description:Cesar A. Hidalgo, Andrew Lippman, Kevin Zeng Hu and Travis Rich QUANTIFY is a generalized framework and JavaScript library to allow rapid multi-dimensional "measurement" of subjective qualities of media. The goal is to make qualitative metrics quantized. For everything from measuring emotional responses of content to the cultural importance of world landmarks, QUANTIFY helps to elicit the raw human subjectivity that fills much of our lives, and makes it programmatically actionable. view site
mit-media-viral-communications-13 | Recast | http://viral.media.mit.edu/projects/recast | description:Dan Sawada, Robert Hemsley, Andrew Lippman Recast is a media curation and distribution platform that enables anyone to create and distribute "news programs" that represent their views of the world from their own perspective. Recast provides a visual scripting interface similar to Scratch, where users can combine a series of logical blocks to query specific scene elements that present their views by drawing from arbitrary video contents, and constructing a story sequence. Recast uses the Constellation system as a backend for querying video content, and uses the Media Matrix as a content distribution platform. view site
mit-media-viral-communications-14 | Sphera | http://um-vr.media.mit.edu?id=3&render=normal | description:Amir Lazarovich, Andrew Lippman One future of media experience lies within a socially connected virtual world. VR started almost 30 years ago and is now wearable, real-time, integrated with sensing, and becoming transparent. Sphera realizes a socially driven 360-degree media space that includes ambient scenery, visual exploration, and integration with friends. By combining an Oculus Rift (VR heads-on display), Microsoft Kinect (depth sensor), and a natural voice command interface, we created a socially connected, 360-degree immersive virtual world for media exploration and selection, as well as big-data manipulation and visualization. view site
mit-media-viral-communications-15 | The Glass Infrastructure (GI) | http://charms.media.mit.edu/static/video/GIdocumentary.mov | description:Andy Lippman, Jon Ferguson and Henry Holtzman This project builds a social, place-based information window into the Media Lab using 30 touch-sensitive screens strategically placed throughout the physical complex and at sponsor sites. The idea is get people to talk among themselves about the work that they jointly explore in a public place. We present Lab projects as dynamically connected sets of "charms" that visitors can save, trade, and explore. The GI demonstrates a framework for an open, integrated IT system and shows new uses for it. view site
mit-media-viral-communications-16 | VR Codes | http://pixels.media.mit.edu | description:Andy Lippman and Grace Woo VR Codes are dynamic data invisibly hidden in television and graphic displays. They allow the display to present simultaneously visual information in an unimpeded way, and real-time data to a camera. Our intention is to make social displays that many can use at once; using VR codes, users can draw data from a display and control its use on a mobile device. We think of VR Codes as analogous to QR codes for video, and envision a future where every display in the environment contains latent information embedded in VR codes. view site
mit-media-viral-communications-17 | WorldLens | http://viral.media.mit.edu/projects/worldlens | description:Jonathan Speiser, Robert Hemsley, Dan Sawada, and Andy Lippman World Lens informs users about newsworthy events that are both popular and obscure. It is a front page that is both navigable and scalable, allowing one to discover as well as track ongoing events. We array in-depth news information across a large multitouch display organized by time, coverage, and geography. Elements are drawn from blogs, the web, newspapers, magazines, and television. Each is presented by a front page that tells the literal story. Readers can fly through the news space, mark items for interest, and activate each. News data is gathered and analyzed by our Glue system, which generates frame-by-frame metadata for video and page analysis for other online material. view site
