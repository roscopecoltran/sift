LTI11344 | Machine Learning in Practice | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11344&SEMESTER=S17 | instructors:Rose, Carolyn description:Machine Learning is concerned with computer programs that enable the behavior of a computer to be learned from examples or experience rather than dictated through rules written by hand.  It has practical value in many application areas of computer science such as on-line communities and digital libraries.  This class is meant to teach the practical side of machine learning for applications, such as mining newsgroup data or building adaptive user interfaces.  The emphasis will be on learning the process of applying machine learning effectively to a variety of problems rather than emphasizing an understanding of the theory behind what makes machine learning work.  This course does not assume any prior exposure to machine learning theory or practice. In the first 2/3 of the course, we will cover a wide range of learning algorithms that can be applied to a variety of problems.  In particular, we will cover topics such as decision trees, rule based classification, support vector machines, Bayesian networks, and clustering. In the final third of the class, we will go into more depth on one application area, namely the application of machine learning to problems involving text processing, such as information retrieval or text categorization.
LTI11345 | Undergrad Independent Study | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11345&SEMESTER=S17 | description:None
LTI11364 | An Introduction to Knowledge-Based Deep Learning and Socratic Coaches | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11364&SEMESTER=S17 | instructors:Baker, James Singh, Rita description:The subject of this course will be deep learning, one of the most dynamic and exciting emerging areas of computer science.  Deep learning deals with and is conquering the problems resulting from the enormous quantity of data that now surrounds us.  Furthermore, the course will explore knowledge-based deep learning, a new methodology invented by the instructor that offers many potential advantages over conventional deep learning. This is a learn-by-doing, team-project based course, which will be divided into four phases.  In phase one, each student will read and present a number of papers describing state-of-the-art deep learning systems and successful applications.  In phase two, each team will implement the system described in one of the papers.  In phase three, each team will scale that implementation to one of the large benchmark datasets.  In phase four, each team will do a special research project implementing a knowledge-based deep learning system based on pending patent applications of Professor Baker. As a potential follow-on for successful projects, students may participate in a summer course on entrepreneurial applications of deep learning or work as interns in a bootstrap startup based on the knowledge-based deep learning projects. Prerequisite: Strong quantitative aptitude, programming skill, ability to quickly absorb new ideas, teamwork skills.
LTI11390 | LTI Minor Project - Juniors | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11390&SEMESTER=S17 | instructors:Black, Alan description:None
LTI11411 | Natural Language Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11411&SEMESTER=S17 | instructors:Frederking, Robert Black, Alan Levin, Lorraine prereq:15122 description:This course will introduce students to the highly interdisciplinary area of Artificial Intelligence known alternately as Natural Language Processing (NLP) and Computational Linguistics. The course aims to cover the techniques used today in software that does useful things with text in human languages like English and Chinese. Applications of NLP include automatic translation between languages, extraction and summarization of information in documents, question answering and dialog systems, and conversational agents. This course will focus on core representations and algorithms, with some time spent on real-world applications. Because modern NLP relies so heavily on Machine Learning, well cover the basics of discrete classification and probabilistic modeling as we go. Good computational linguists also know about Linguistics, so topics in linguistics (phonology, morphology, and syntax) will be covered when fitting. From a software engineering perspective, there will be an emphasis on rapid prototyping, a useful skill in many other areas of Computer Science. In particular, we will introduce some high-level languages (e.g., regular expressions and Dyna) and some scripting languages (e.g., Python and Perl) that can greatly simplify prototype implementation.
LTI11421 | GRAMMARS &amp; LEXICONS: Grammars &amp; Lexicons | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11421&SEMESTER=F16 | instructors:Levin, Lorraine Mitamura, Teruko description:Grammars and Lexicons is an introductory graduate course on linguistic data analysis and theory, focusing on methodologies that are suitable for computational implementations. The course covers major syntactic and morphological phenomena in a variety of languages. The emphasis will be on examining both the diversity of linguistic structures and the constraints on variation across languages. Students will be expected to develop and defend analyses of data, capturing linguistic generalizations and making correct predictions within and across languages. The goal is for students to become familiar with the range of phenomena that occur in human languages so that they can generalize the insights into the design of computational systems. The theoretical framework for syntactic and lexical analysis will be Lexical Functional Grammar. Grades will be based on problem sets and take-home exams.
LTI11423 | ConLanging: Lrng. Ling. &amp; Lang Tech via Constru Artif. Lang. | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11423&SEMESTER=S17 | instructors:Levin, Lorraine Black, Alan description:TBA
LTI11441 | Machine Learning for Text Mining | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11441&SEMESTER=S17 | instructors:Yang, Yiming description:This course provides a comprehensive introduction to the theory and implementation of algorithms for organizing and searching large text collections. The first half of the course studies text search engines for enterprise and Web environments; the open-source Indri search engine is used as a working example. The second half studies text mining techniques such as clustering, categorization, and information extraction. Programming assignments give hands-on experience with document ranking algorithms, categorizing documents into browsing hierarchies, and related topics.
LTI11442 | Search Engines | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11442&SEMESTER=S17 | instructors:Callan, James description:This course studies the theory, design, and implementation of text-based search engines. The core components include statistical characteristics of text, representation of information needs and documents, several important retrieval models, and experimental evaluation. The course also covers common elements of commercial search engines, for example, integration of diverse search engines into a single search service (federated search, vertical search), personalized search results, diverse search results, and sponsored search. The software architecture components include design and implementation of large-scale, distributed search engines.
LTI11485 | Basics of Deep Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11485&SEMESTER=S17 | instructors:Ramakrishnan, Bhiksha prereq:(15112) and (21120) and (21241) description:Deep learning is a subfield of AI that has lately taken the world by storm.  Deep learning systems have been shown to able to recognize speech almost as well as humans, recognize images better than humans, read the web and answer questions, learn on their own to play games, beat humans at the toughest games like go and even speak more clearly than a human can.  Deep learning currently dominates research in a variety of scientific areas, including text and language processing, data mining, speech processing, computer vision, robotics, and AI. Deep learning based products and services dominate the market in many areas. Whether youre using Google or social media, buying a plane ticket, browsing an online retailer, investing in stocks, or hailing an Uber, you are interacting with a deep learning system. Knowledge of deep learning is considered a valuable asset, and sometimes even essential, in the employment market.  So what exactly is this mysterious beast?  In this course we will study the basics of deep learning systems, starting from their humble beginnings as attempts to understand human cognition, their adolescence as artificial neural networks, leading on to the current complex systems that can perform astounding tasks.  Students will learn both the underlying principles through a series of 13 lectures, and to actually implement and manipulate these systems for various tasks through a series of lab exercises.
LTI11490 | LTI Minor Project - Seniors | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11490&SEMESTER=S17 | instructors:Black, Alan description:None
LTI11492 | Speech Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11492&SEMESTER=F16 | instructors:Black, Alan description:to be determined by the department.
LTI11590 | LTI Minor Project - Advanced | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11590&SEMESTER=S17 | instructors:Black, Alan description:None
LTI11601 | Coding &amp; Algorithms Bootcamp: Coding Boot Camp | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11601&SEMESTER=F16 | instructors:Starzl, Ravi Brown, Ralf description:This course has one goal: To ingrain as deep a mastery of fundamental algorithm and coding skills as possible in the timeframe of this course. We will seek to specifically to maximize your chances of superior performance in any coding interview, improving your ability to form structured thoughts with respect to algorithmic problem solving, improve your ability to describe and plan solutions to problems, and develop further your ability to translate your thoughts into code intuitively and explain that code to others.
LTI11602 | Coding and Mathematics Intensive Practicum | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11602&SEMESTER=F16 | instructors:Starzl, Ravi description:This course number is intended for individual study with faculty.
LTI11611 | Natural Language Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11611&SEMESTER=S17 | instructors:Frederking, Robert Black, Alan Levin, Lorraine description:None
LTI11621 | Machine Learning BootcampThis Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11621&SEMESTER=F16 | description:Machine Learning Bootcamp to prepare students for 10-601. Not a requirement.
LTI11623 | ConLanging: Lrng. Ling.&amp;Lang Tech via Constru Artif. Lang. | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11623&SEMESTER=S17 | instructors:Levin, Lorraine Black, Alan description:tba
LTI11630 | MCDS Practicum Internship | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11630&SEMESTER=F16 | instructors:Nyberg, Eric Tomasic, Anthony description:The MCDS Practicum course is used for recording CDS students summer internships for the MCDS Program.  Section A is used for 7-month internship opportunities Section B is used for Returning Fall Analytic students who DO NOT attain a 7-mo Internships.  Section R is used to record MCDS students Internship Requirements
LTI11631 | Seminar in Data Science | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11631&SEMESTER=F16 | instructors:Tomasic, Anthony description:This course provides the MCDS students with a basic understanding of Data Science as an emerging scientific discipline, with interdisciplinary perspectives from computer science, business, and information policy / security. Students will read and discuss relevant publications, and attend presentations by guest speakers. Grading will be based on homework assignments related to the material covered in class sessions.  This course is for MCDS students only.
LTI11632 | Data Science Analytics Capstone | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11632&SEMESTER=F16 | instructors:Tomasic, Anthony description:The MCDS-Capstone course is the final large team project for MCDS master degree students. Students take 11-632 as a combined capstone course for process  outcomes. This process  outcome course evaluates the project teams use of software engineering methodology and evaluates the outcomes of the project.
LTI11633 | MCDS Independent Study: MCDS Independent Study | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11633&SEMESTER=S17 | instructors:Nyberg, Eric description:An independent study course is designed by the student to cover study of a particular area of interest too the student and is used when there is no formal course available in that subject area.  This course is for MCDS Students Only
LTI11634 | MCDS Capstone Planning Seminar: MCDS Capstone Planning Seminar | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11634&SEMESTER=S17 | instructors:Nyberg, Eric description:This course (open to MCDS students only) is a project based course where students exercise course work in a team based project. The course covers project management, a vision statement, requirements analysis, software architecture, functional specification, and an implementation of a prototype or scientific experiment. In addition, presentation skills are emphasized with multiple presentations throughout the semester.
LTI11641 | Machine Learning for Text Mining | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11641&SEMESTER=S17 | instructors:Yang, Yiming description:TBA
LTI11642 | Search Engines | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11642&SEMESTER=S17 | instructors:Callan, James description:This course studies the theory, design, and implementation of text-based search engines. The core components include statistical characteristics of text, representation of information needs and documents, several important retrieval models, and experimental evaluation. The course also covers common elements of commercial search engines, for example, integration of diverse search engines into a single search service (federated search, vertical search), personalized search results, diverse search results, and sponsored search. The software architecture components include design and implementation of large-scale, distributed search engines.
LTI11661 | Language and Statistics: Language &amp; Statistics | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11661&SEMESTER=F16 | instructors:Rosenfeld, Ronald description:Language technologies (search, text mining, information retrieval, speech recognition, machine translation, question answering, biological sequence analysis...) are at the forefront of this centurys information revolution.  In addition to their use of machine learning, these technologies rely centrally on classic statistical estimation techniques.   Yet most CS and engineering undergraduate programs do not prepare students in this area beyond an introductory probstats course.  This course is designed to plug this hole.  The goal of Language and Statistics is to ground the data-driven techniques used in language technologies in sound statistical methodology.   We start by formulating various language technology problems in both an information theoretic framework (the source-channel paradigm) and a Bayesian framework (the Bayes classifier).  We then discuss the statistical properties of words, sentences, documents and whole languages, and the computational formalisms used to represent language.  These discussions naturally lead to specific concepts in statistical estimation.  Topics include: Zipfs distribution and type-token curves; point estimators, Maximum Likelihood estimation, bias and variance, sparseness, smoothing and clustering; interpolation, shrinkage, and backoff; entropy, cross entropy and mutual information;  decision tree models applied to language; latent variable models and the EM algorithm; hidden Markov models; exponential models and maximum entropy; semantic modeling and dimensionality reduction; probabilistic context-free grammars and syntactic language models.  The course is designed for LTI  SCS graduate students, but others are welcome.  CS UG upperclassmen whove taken it have done well, though they found it challenging.  The 11-661 version does not require the course project.  Prerequisites: Strong quantitative aptitude.  Comfort with basic UG-level probability.  Some programming skill.
LTI11663 | Applied Machine Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11663&SEMESTER=S17 | instructors:Rose, Carolyn description:Machine Learning is concerned with computer programs that enable the behavior of a computer to be learned from examples or experience rather than dictated through rules written by hand.  It has practical value in many application areas of computer science such as on-line communities and digital libraries.  This class is meant to teach the practical side of machine learning for applications, such as mining newsgroup data or building adaptive user interfaces.  The emphasis will be on learning the process of applying machine learning effectively to a variety of problems rather than emphasizing an understanding of the theory behind what makes machine learning work.  This course does not assume any prior exposure to machine learning theory or practice. In the first 2/3 of the course, we will cover a wide range of learning algorithms that can be applied to a variety of problems.  In particular, we will cover topics such as decision trees, rule based classification, support vector machines, Bayesian networks, and clustering. In the final third of the class, we will go into more depth on one application area, namely the application of machine learning to problems involving text processing, such as information retrieval or text categorization.
LTI11675 | Big Data Systems in Practice | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11675&SEMESTER=S17 | instructors:Starzl, Ravi description:To be determined
LTI11676 | Big Data Analytics: Big Data Analytics | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11676&SEMESTER=F16 | instructors:Starzl, Ravi description:TBD
LTI11685 | Basics of Deep Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11685&SEMESTER=S17 | instructors:Ramakrishnan, Bhiksha description:Deep learning is a subfield of AI that has lately taken the world by storm. Deep learning systems have been shown to able to recognize speech almost as well as humans, recognize images better than humans, read the web and answer questions, learn on their own to play games, beat humans at the toughest games like go and even speak more clearly than a human can. Deep learning currently dominates research in a variety of scientific areas, including text and language processing, data mining, speech processing, computer vision, robotics, and AI. Deep learning based products and services dominate the market in many areas. Whether youre using Google or social media, buying a plane ticket, browsing an online retailer, investing in stocks, or hailing an Uber, you are interacting with a deep learning system. Knowledge of deep learning is considered a valuable asset, and sometimes even essential, in the employment market. So what exactly is this mysterious beast? In this course we will study the basics of deep learning systems, starting from their humble beginnings as attempts to understand human cognition, their adolescence as artificial neural networks, leading on to the current complex systems that can perform astounding tasks. Students will learn both the underlying principles through a series of 13 lectures, and to actually implement and manipulate these systems for various tasks through a series of lab exercises.
LTI11690 | MIIS Directed Study | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11690&SEMESTER=S17 | instructors:Callan, James description:to be determined by the department
LTI11691 | Mathematical Foundations for Data Science | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11691&SEMESTER=F16 | instructors:Ramakrishnan, Bhiksha description:There is a familiar picture regarding software development: it is often delivered late, over-budget, and lacking important features. There is often an inability to capture the customers actual way of accomplishing work, and then creating a realistic project plan. This will be especially important as software development in the life sciences involves creating applications that are relatively new to the industry.     The course will introduce students to the Balanced Framework of project management process that assists biotechnology organizations in planning and managing software projects that support their product development. It provides the identification, structuring, evaluation and ongoing management of the software project that deliver the benefits expected from the organizations investments. It focuses on the delivery of business value being initiated by the project. It helps an organization answer the basic question Are the things we are doing providing value to the business?     In this course, students will learn how to examine and explain customer processes and create requirements that reflect how work is actually done. Students will additionally create a software project plan that incorporates: problem framing; customer workflow, planning, project tracking, monitoring, and measurement.
LTI11692 | Speech Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11692&SEMESTER=F16 | instructors:Black, Alan description:To be determined by the department
LTI11695 | Competitive Engineering | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11695&SEMESTER=S17 | instructors:Vu, Du (John) description:In the second core course, students will be tasked with building a software application prototype for a biotech/pharmaceutical firm. Students will be introduced to a particular firm (through one of the program advisors) and will learn how to conduct and develop requirements analysis and convert that into feature definition. The customer requirements are often a moving target: theyre influenced by the emergence of competitive alternatives (e.g. internal consultants, off-the-shelf software) and also by the team interaction with each others. Students will learn to create a product that best captures the best balance of the customer priorities and feasibility and distinguishing it from competitive alternatives. They will then use this learning to develop their respective prototypes. At the conclusion of the term, teams will compete with each other to determine which teams product is superior. In addition to having to apply various aspects of software development and computational learning, the course will help to provide students with some key insights into how biotech/pharmaceutical businesses operate.        In addition to concepts regarding market demand, students will learn how to aggregate and synthesize information related to demand, pricing and competition. They will then apply this learning to define and prioritize market driven requirements as it relates to a product. This information will then be used to build a product development plan. Students will utilize methods to enhance product quality and customer satisfaction: benchmarking; industry and customer analyses; project metrics, and a range of customer relationship management tools.
LTI11696 | MIIS Capstone Planning Seminar | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11696&SEMESTER=S17 | instructors:Brown, Ralf description:The MIIS Capstone Planning Seminar prepares students to complete the MIIS Capstone Project in the following semester.  Students are organized into teams that will work together to complete the capstone project.  They define project goals, requirements, success metrics, and deliverables; and they identify and acquires data, software, and other resources required for successful completion of the project. The planning seminar must be completed in the semester prior to taking the capstone project.
LTI11699 | MSBIC Program Capstone | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11699&SEMESTER=S17 | instructors:Vu, Du (John) Starzl, Ravi description:The final term will integrate all of the acquired learning in the program towards the development of a formal business plan and software product beta. The effort involved in the capstone project is quite intense and will consist of approximately three months of full time work for each student. The expected deliverables (features to be developed, business plan, technical documentation, etc.) must be agreed to by the course instructor at the outset of the course. The capstone can either encompass the development of an industry sponsored software project or a software product intended for entrepreneurial startup. Students are expected to showcase their business and software projects and elicit feedback from academics, industry professionals, investors, and business executives. This phase also acts as an incubation period for companies that will be launched from the program.
LTI11700 | LTI Colloquium | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11700&SEMESTER=S17 | instructors:Hauptmann, Alexander description:The LTI colloquium is a series of talks related to language technologies. The topics include but are not restricted to Computational Linguistics, Machine Translation, Speech Recognition and Synthesis, Information Retrieval, Computational Biology, Machine Learning, Text Mining, Knowledge Representation, Computer-Assisted Language Learning and Intelligent Language Tutoring. To get credit of the course, students are required to write either a short critique of one of the presentations or a comparison of two.
LTI11711 | Algorithms for NLP | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11711&SEMESTER=F16 | instructors:Frederking, Robert Berg-Kirkpatrick, Taylor description:Algorithms for NLP is an introductory graduate-level course on the computational properties of natural languages and the fundamental algorithms for processing natural languages. The course will provide an in-depth presentation of the major algorithms used in NLP, including Lexical, Morphological, Syntactic and Semantic analysis, with the primary focus on parsing algorithms and their analysis.
LTI11712 | Lab in NLP | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11712&SEMESTER=S17 | instructors:Frederking, Robert description:The Self-Paced Lab in NLP Algorithms is intended to complement the 11-711 lecture course by providing a chance for hands-on, in-depth exploration of various NLP paradigms. Students will study a set of on-line course materials and complete a set of programming assignments illustrating the concepts taught in the lecture course. Timing of individual assignments is left up to the student, although all assignments must be successfully completed and turned in before the end of the semester for the student to receive credit for the course.
LTI11714 | Tools for NLP | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11714&SEMESTER=F16 | instructors:Hovy, Eduard description:This course is designed as a hands-on lab to help students interested in NLP build their own compendium of the open-source tools and resources available online.  Ideally taken in the first semester, the course focuses on one basic topic every two weeks, during which each student will download, install, and play with two or three packages, tools, or resources, and compare notes.  The end-of-semester assignment will be to compose some of the tools into a system that does something interesting.  We will cover a range, from the most basic tools for sentence splitting and punctuation removal through resources such as WordNet and the Penn Treebank to parsing and Information Extraction engines.
LTI11716 | Graduate Seminar on Dialog Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11716&SEMESTER=F16 | instructors:Rudnicky, Alexander description:Dialog systems and processes are becoming an increasingly vital area of interest both in research and in practical applications. The purpose of this course will be to examine, in a structured way, the literature in this area as well as learn about ongoing work.  The course will cover traditional approaches to the problem, as exemplified by the work of Grosz and Sidner, as well as more recent work in dialog, discourse and evaluation, including statistical approaches to problems in the field. We will select several papers on a particular topic to read each week. While everyone will do all readings, a presenter will be assigned to overview the paper and lead the discussion. On occasion, a researcher may be invited to present their own work in detail and discuss it with the group. A student or researcher taking part in the seminar will come away with a solid knowledge of classic work on dialog, as well as familiarity with ongoing trends.
LTI11719 | Computational Models of Discourse Analysis | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11719&SEMESTER=S17 | instructors:Rose, Carolyn description:Discourse analysis is the area of linguistics that focuses on the structure of language above the clause level.  It is interesting both in the complexity of structures that operate at that level and in the insights it offers about how personality, relationships, and community identification are revealed through patterns of language use.  A resurgence of interest in topics related to modeling language at the discourse level is in evidence at recent language technologies conferences.  This course is designed to help students get up to speed with foundational linguistic work in the area of discourse analysis, and to use these concepts to challenge the state-of-the-art in language technologies for problems that have a strong connection with those concepts, such as dialogue act tagging, sentiment analysis, and bias detection.  This is meant to be a hands on and intensely interactive course with a heavy programming component.  The course is structured around 3 week units, all but the first of which have a substantial programming assignment structured as a competition (although grades will not be assigned based on ranking within the competition, rather grades will be assigned based on demonstrated comprehension of course materials and methodology).
LTI11721 | Grammars and Lexicons | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11721&SEMESTER=F16 | instructors:Levin, Lorraine Mitamura, Teruko description:Grammars and Lexicons is an introductory graduate course on linguistic data analysis and theory, focusing on methodologies that are suitable for computational implementations. The course covers major syntactic and morphological phenomena in a variety of languages. The emphasis will be on examining both the diversity of linguistic structures and the constraints on variation across languages. Students will be expected to develop and defend analyses of data, capturing linguistic generalizations and making correct predictions within and across languages. The goal is for students to become familiar with the range of phenomena that occur in human languages so that they can generalize the insights into the design of computational systems. The theoretical framework for syntactic and lexical analysis will be Lexical Functional Grammar. Grades will be based on problem sets and take-home exams.
LTI11723 | Linguistics Lab | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11723&SEMESTER=S17 | instructors:Levin, Lorraine description:Formal Semantics is an introductory graduate course on formal linguistic semantics: Given a syntactic analysis of a natural language utterance, how can one assign the correct meaning representation to it, using a formal logical system? More details TBA.
LTI11726 | Meaning in Language Lab (Self Paced) | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11726&SEMESTER=S17 | instructors:Rose, Carolyn description:The self-paced Meaning in Language Lab is intended to follow-up on the 11-725 lecture course (Meaning in Language) by providing a chance for hands-on, in-depth, computational exploration of various semantics and pragmatics research topics. The course is self-paced and there will be no scheduled lecture times, however, students are welcome to set up meetings with the instructor as desired, and students who prefer to have a weekly or bi-monthly regularly scheduled meeting with the instructor are welcome to arrange for that. If there is sufficient interest, an informal reading group may be formed to supplement the lab work.    Students will design their own project, which they will discuss with the instructor for approval. Students are encouraged to select a topic from semantics, pragmatics, or discourse analysis, such as entailment, evidentiality, implicature, information status, or rhetorical structure, and a topic from language technologies, such as sentiment analysis or summarization, and explore how the linguistic topic applies to some aspect of the chosen language technology. Students are encouraged to contrast symbolic, formal, and knowledge based approaches with empirical approaches.    Each student will work independently. If multiple students work as a team on a particular topic, each should choose an approach that is different from the approaches used by the other students working on the same problem. Students will be responsible to set up a web page, blog, or wiki to post progress reports and other supporting documents, data, and analyses. The web space will be checked by the instructor periodically , and thus should be kept updated in order to reflect on-going progress. The web space will also serve as a shared project space in the case that students are working in a team for the project.
LTI11727 | Computational Semantics for NLP | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11727&SEMESTER=S17 | instructors:Hovy, Eduard Mitamura, Teruko description:This course surveys semantics from a language processing perspective.  It is divided into three main sections supplemented with a substantive semester-long computational project.  The first section addresses traditional topics of computational semantics and semantic processing and representation systems.  The second focuses on computational lexical semantics, including resources such as WordNet, Framenet, and some word-based ontologies, and their computational applications, such as word sense disambiguation, entailment, etc., and briefly the semantic web.  The third section covers modern statistics-based distributional models of semantics.  Each week focuses on one topic, covered by the lecturers, and will include one or two core introductory readings plus several optional more advanced readings.  All students will read and discuss the introductory readings while each student will be expected to read advanced papers on at least two topics.
LTI11731 | Machine Translation and Sequence-to-Sequence Models | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11731&SEMESTER=S17 | instructors:Neubig, Graham description:Instructors: Graham Neubig.  Prerequisites: This course has no official pre-requisites, although 11-711 Algorithms for NLP or 10-701 Machine Learning would be helpful. Course   Machine Translation and Sequence-to-Sequence Models is an introductory graduate-level course surveying the primary approaches and methods for developing systems to translate between human languages, or other sequential data.  The main objective of the course is to obtain basic understanding and implementation skills for modern methods for MT and sequence transduction, including how to design models, how to learn the model parameters, how to search for the best output, and how to create training data. The course will focus on machine translation, but also briefly cover tasks such as dialog response generation, image caption generation, and others.
LTI11732 | Self-Paced Lab: MT | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11732&SEMESTER=S17 | instructors:Neubig, Graham prereq:11731 description:The Self-Paced Lab in MT is intended to complement the 11-731 lecture course by providing a chance for hands-on, in-depth exploration of various MT paradigms. MT faculty will present a set of possible topics to the students enrolled in the course. The students will indicate their first and second choices for lab projects, and will then be matched to a lab project advisor. At the end of the semester, the students will present the results of their projects in class, and submit a short paper describing them.
LTI11736 | Graduate Seminar on Endangered Languages | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11736&SEMESTER=F16 | instructors:Black, Alan Frederking, Robert Levin, Lorraine description:The purpose of this seminar is to allow students to better understand the linguistic, social and political issues when working with language technologies for endangered languages. Often in LTI we concentrate on issues of modeling with small amounts of data, or designing optimal strategies for collecting data, but ignore many of wider practical issues that appear when working with endangered languages.     This seminar will consist of reading books and papers, and having participants give presentations; a few invited talks (e.g. from field linguists, and language advocates) will also be included. It will count for 6 units of LTI course credit. It may be possible for interested students to also carry out a related 6-unit project as a lab.
LTI11741 | Machine Learning for Text Mining | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11741&SEMESTER=S17 | instructors:Yang, Yiming description:This course studies the theory, design, and implementation of text-based information systems. The Information Retrieval core components of the course include statistical characteristics of text, representation of information needs and documents, several important retrieval models (Boolean, vector space, probabilistic, inference net, language modeling), clustering algorithms, automatic text categorization, and experimental evaluation. The software architecture components include design and implementation of high-capacity text retrieval and text filtering systems. A variety of current research topics are also covered, including cross-lingual retrieval, document summarization, machine learning, topic detection and tracking, and multi-media retrieval.      Prerequisites:      Programming and data-structures at the level of 15-212 or higher.  Algorithms comparable to the undergraduate CS algorithms course (15-451) or higher.  Basic linear algebra (21-241 or 21-341).   Basic statistics (36-202) or higher.
LTI11743 | Self-Paced Lab: IR | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11743&SEMESTER=S17 | instructors:Yang, Yiming prereq:11441 or 11442 or 11641 or 11642 or 11741 description:Advanced Information Retrieval Seminar and Lab is a seminar that focuses on current research in Information Retrieval. The seminar covers recent research on subjects such as retrieval models, text classification, information gathering, fact extraction, information visualization, summarization, text data mining, information filtering, collaborative filtering, question answering systems, and portable information systems. Other topics are drawn from recent SIGIR, Digital Libraries, TREC, Machine Learning, and AAAI conferences. Course content varies from year to year.  Students not taking the course for credit are welcome to audit or sit in on the course, subject to availability of space.
LTI11745 | Advanced Statistical Learning Seminar | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11745&SEMESTER=F16 | instructors:Yang, Yiming description:This seminar aims to deepen the participants understanding of the theoretical foundation of statistical learning and applications, to broaden their knowledge of new techniques, directions and challenges in the field, and to inspire research ideas through class-room discussions.  In the past years, this seminar was structured as a 12-unit course in the form of group-reading, presenting and discussing the book (chapter by chapter) of The Elements of Statistical Learning: Data Mining, Inference, and Prediction by Trevor Hastie et al. In the fall of 2014, we will have a 6-unit seminar, focusing on New Methods in Large-scale Structured Learning, with selected papers from the past 2-3 years of ICML, NIPS, KDD, JMLR or the like, plus related background reading. We will meet once a week, one topic per week (1-2 papers), with presentations rotating among participants. In each week, the assigned presenter starts with the questions from all the participants (collected by email) about the current topic, followed by a presentation on that topic and leads the discussion. All the students are required to read the assigned paper(s) of the week before the class, and email their questions to the presenter (CC to everybody). By the end of the semester, each student will individually write a short 3-4-page white paper outlining a research proposal for new work extending one of the research areas discussed in class.  There will be no exams or homework; the grading is based on class participation, quality of the seminar presentation(s), questions submitted for each class and discussions, and the final brief paper. Prerequisites: Intro machine learning and related courses
LTI11751 | Speech Recognition and Understanding | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11751&SEMESTER=F16 | instructors:Metze, Florian description:The technology to allow humans to communicate by speech with machines or by which machines can understand when humans communicate with each other is rapidly maturing. This course provides an introduction to the theoretical tools as well as the experimental practice that has made the field what it is today. We will cover theoretical foundations, essential algorithms, major approaches, experimental strategies and current state-of-the-art systems and will introduce the participants to ongoing work in representation, algorithms and interface design. This course is suitable for graduate students with some background in computer science and electrical engineering, as well as for advanced undergraduates. Prerequisites: Sound mathematical background, knowledge of basic statistics, good computing skills. No prior experience with speech recognition is necessary. This course is primarily for graduate students in LTI, CS, Robotics, ECE, Psychology, or Computational Linguistics. Others by prior permission of instructor.
LTI11753 | Advanced Laboratory in Speech Recognition | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11753&SEMESTER=S17 | instructors:Metze, Florian description:The technology to allow humans to communicate by speech with machines or by which machines can understand when humans communicate with each other is rapidly maturing. While the 11-751 speech course focussed on an introduction to the theoretical foundations, essential algorithms, major approaches, and strategies for current state-of-the-art systems, the 11-753 speech lab complements the education by concentrating on the experimental practice in developing speech recognition and understanding speech-based systems, and by getting hands-on experience on relevant research questions using state-of-the art tools. Possible problem sets include both core speech recognition technology, and the integration of speech-based components into multi-modal, semantic, learning, or otherwise complex systems and interfaces.
LTI11754 | Project Course: Dialogue Systems | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11754&SEMESTER=S17 | instructors:Black, Alan Rudnicky, Alexander description:This course will teach participants how to implement a complete spoken language system while providing opportunities to explore research topics of interest in the context of a functioning system. The course will produce a complete implementation of a system to access and manipulate email through voice only, for example to allow users to interact with the mail system over a telephone while away from their computer. In doing so the class will address the component activities of spoken language system building. These include, but are not limited to, task analysis and language design, application-specific acoustic and language modeling, grammar design, task design, dialog management, language generation and synthesis. The course will place particular emphasis on issues in task design and dialog management and on issues in language generation and synthesis.     For Fall, we will implement a simple telephone-based information access application. The domain is bus schedules (see http://www.speech.cs.cmu.edu/BusLine for a web-based interface to this domain) and the goal will be to create one or more usable applications that can provide a real service and can be deployed for actual use by the University community. Participants will chose individual components of the system to concentrate on and will collaborate to put together the entire system. It is perfectly acceptable for several individuals to concentrate on a single component, particularly if their work will exemplify alternative approaches to the same problem.
LTI11755 | Machine Learning for Signal Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11755&SEMESTER=F16 | instructors:Ramakrishnan, Bhiksha description:Signal Processing is the science that deals with extraction of information from signals of various kinds. This has two distinct aspects -- characterization and categorization. Traditionally, signal characterization has been performed with mathematically-driven transforms, while categorization and classification are achieved using statistical tools.     Machine learning aims to design algorithms that learn about the state of the world directly from data.     A increasingly popular trend has been to develop and apply machine learning techniques to both aspects of signal processing, often blurring the distinction between the two.     This course discusses the use of machine learning techniques to process signals. We cover a variety of topics, from data driven approaches for characterization of signals such as audio including speech, images and video, and machine learning methods for a variety of speech and image processing problems.
LTI11761 | Language and Statistics: Language &amp; Statistics | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11761&SEMESTER=F16 | instructors:Rosenfeld, Ronald description:Language technologies (search, text mining, information retrieval, speech recognition, machine translation, question answering, biological sequence analysis...) are at the forefront of this centurys information revolution.  In addition to their use of machine learning, these technologies rely centrally on classic statistical estimation techniques.   Yet most CS and engineering undergraduate programs do not prepare students in this area beyond an introductory probstats course.  This course is designed to plug this hole.  The goal of Language and Statistics is to ground the data-driven techniques used in language technologies in sound statistical methodology.   We start by formulating various language technology problems in both an information theoretic framework (the source-channel paradigm) and a Bayesian framework (the Bayes classifier).  We then discuss the statistical properties of words, sentences, documents and whole languages, and the computational formalisms used to represent language.  These discussions naturally lead to specific concepts in statistical estimation.  Topics include: Zipfs distribution and type-token curves; point estimators, Maximum Likelihood estimation, bias and variance, sparseness, smoothing and clustering; interpolation, shrinkage, and backoff; entropy, cross entropy and mutual information;  decision tree models applied to language; latent variable models and the EM algorithm; hidden Markov models; exponential models and maximum entropy; semantic modeling and dimensionality reduction; probabilistic context-free grammars and syntactic language models.  The course is designed for LTI  SCS graduate students, but others are welcome.  CS UG upperclassmen whove taken it have done well, though they found it challenging.  The 11-661 version does not require the course project.  Prerequisites: Strong quantitative aptitude.  Comfort with basic UG-level probability.  Some programming skill.
LTI11763 | Structured Prediction for Language and other Discrete DataThis Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11763&SEMESTER=S17 | instructors:Berg-Kirkpatrick, Taylor description:This course seeks to cover statistical modeling techniques for  discrete, structured data such as text.  It brings together  content previously covered in Language and Statistics 2 (11-762)  and Information Extraction (10-707 and 11-748), and aims to define  a canonical set of models and techniques applicable to problems in  natural language processing, information extraction, and other  application areas.  Upon completion, students will have a broad  understanding of machine learning techniques for structured  outputs, will be able to develop appropriate algorithms for use in  new research, and will be able to critically read related  literature.  The course is organized around methods, with example  tasks introduced throughout.
LTI11775 | Large-Scale Multi-media Analysis | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11775&SEMESTER=S17 | instructors:Hauptmann, Alexander Metze, Florian description:TBA
LTI11776 | Human Communication and Multimodal Computation | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11776&SEMESTER=F16 | instructors:Morency, Louis-Philippe description:Human face-to-face communication is a little like a dance, in that participants continuously adjust their behaviors based on verbal and nonverbal displays and signals. Human interpersonal behaviors have long been studied in linguistic, communication, sociology and psychology. The recent advances in machine learning, pattern recognition and signal processing enabled a new generation of computational tools to analyze, recognize and predict human communication behaviors during social interactions. This new research direction have broad applicability, including the improvement of human behavior recognition, the synthesis of natural animations for robots and virtual humans, the development of intelligent tutoring systems, and the diagnoses of social disorders (e.g., autism spectrum disorder).   This is a graduate course primarily for students in LTI, HCII and Robotics; others, for example (undergraduate) students of CS or professional masters, by prior permission of the instructor. Students should have proper academic background in probability, statistic and linear algebra. Previous experience in machine learning is suggested but not obligatory. Programming knowledge in Matlab and/or Python is recommended.
LTI11777 | Advanced Multimodal Machine Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11777&SEMESTER=S17 | instructors:Morency, Louis-Philippe Baltrusaitis, Tadas description:Multimodal machine learning (MMML) is a vibrant multi-disciplinary research field which addresses some of the original goals of artificial intelligence by integrating and modeling multiple communicative modalities, including linguistic, acoustic and visual messages. With the initial research on audio-visual speech recognition and more recently with language  vision projects such as image and video captioning, this research field brings some unique challenges for multimodal researchers given the heterogeneity of the data and the contingency often found between modalities. This course will teach fundamental mathematical concepts related to MMML including multimodal alignment and fusion, heterogeneous representation learning and multi-stream temporal modeling. We will also review recent papers describing state-of-the-art probabilistic models and computational algorithms for MMML and discuss the current and upcoming challenges.  The main technical topics are: (1) multimodal representation learning, including multimodal auto-encoder and deep learning, (2) multimodal component analysis and fusion, including deep canonical correlation analysis and multi-kernel learning, (3) multimodal alignment and multi-stream modeling, including multi-instance learning and multimodal recurrent neural networks, and (4) multi-sensory computational modeling, including nonparametric Bayesian networks and multimodal hierarchical Dirichlet  processes. The course will also discuss many of the recent applications of MMML including multimodal affect recognition, image and video captioning and cross-modal multimedia retrieval.
LTI11782 | Self-Paced Lab for Computational Biology | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11782&SEMESTER=S17 | instructors:Xing, Eric prereq:10810 description:Students will choose from a set of projects designed by the instructor. Students will also have the option of designing their own projects, subject to instructor approval. For the students who had completed a project in the 10-810 course, they can either switch to another project, or continue working on the previous project by aiming a significant progress (subject to instructor approval). Each student will work independently. If more than one student work on a particular topic, each should choose an approach that is different from the approaches used by the other students working on the same problem. The students need to begin with a project proposal to outline the high-level ideas, tasks, and goals of the problem, and plan of experiments and/or analysis. The instructor will consult with you on your ideas , but the final responsibility to define and execute an interesting piece of work is yours. Your project will have two final deliverables: 1. a writeup in the form of a NIPS paper (8 pages maximum in NIPS format, including references), worth 60 of the project grade, and 2. a research seminar presentation of your work at the end of the semester, worth 20 of the project grade. In addition, you must turn in a midway progress report (5 pages maximum in NIPS format, including references) describing the results of your first experiments, worth 20 of the project grade. Note that, as with any conference, the page limits are strict Papers over the limit will not be considered. The grading of your project are based on overall scientific quality, novelty, writing, and clarity of presentation. We expect your final report to be of conference-paper quality, and you are expected to also deliver software implementation of your algorithmic results.
LTI11783 | Self-Paced Lab: Rich Interaction in Virtual World | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11783&SEMESTER=S17 | instructors:Metze, Florian prereq:11751 and 18781 and 18799 description:Massively Multi-player Online Role-Playing Games have evolved into Virtual Worlds (VWs), and are creating ever richer environments for experimentation on all aspects of human to human, or human to machine communication, as well as for information discovery and access. So far, interaction has been constrained by the limited capabilities of keyboards, joysticks, or computer mice. This creates an exciting opportunity for explorative research on speech input and output, speech-to-speech translation, or any aspect of language technology. Of particular interest will be a combination with other novel real world (RW) input, or output devices, such as mobile phones or portable games consoles, because they can be used to control the VW, or make it accessible everywhere in RW. Language technologies in particular profit from context awareness, because domain adaptation can be performed. For scientific experimentation in that area, Virtual Worlds offer the opportunity to concentrate on algorithms, because context sensors can be written with a few lines of code, without the need for extra hardware sensors. Algorithms can also run continuously, without the need for specific data collection times or places, because the VW is always on.    In this lab, we will enhance existing clients to virtual worlds so that they can connect to various speech and language related research systems developed at LTI and CMUs Silicon Valley campus. The lab will be held jointly at the CMUs Pittsburgh and Silicon Valley Campuses. We will eat our own dog food, so the goal will be to hold the last session entirely in a virtual class room, which will by that time include speech control of virtual equipment, speech-to-speech translation, and some devices that can be controlled using non-PC type equipment, like mobile phones. Eventually, this virtual room or the know-how gathered
LTI11785 | Lab Course on Deep Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11785&SEMESTER=F16 | instructors:Ramakrishnan, Bhiksha description:to be determined by department
LTI11791 | Design &amp; Engineering of Intelligent Information Systems | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11791&SEMESTER=S17 | instructors:Nyberg, Eric description:The Software Engineering for IT sequence combines classroom material and assignments in the fundamentals of software engineering (11-791) with a self-paced, faculty-supervised directed project (11-792). The two courses cover all elements of project design, implementation, evaluation, and documentation.    For students intending to complete both courses, it is recommended that the project design and proof-of-concept prototype be completed and approved by the faculty advisor before the start of 11-792, if possible. Students may elect to take only 11-791; however, if both parts are taken, they should be taken in proper sequence.
LTI11792 | Intelligent Information Systems Project | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11792&SEMESTER=S17 | instructors:Nyberg, Eric prereq:11791 or 15393 description:The Software Engineering for IS sequence combines classroom material and assignments in the fundamentals of software engineering (11-791) with a self-paced, faculty-supervised directed project (11-792). The two courses cover all elements of project design, implementation, evaluation, and  documentation. Students may elect to take only 11-791; however, if both parts are taken, they should be taken in proper sequence. Prerequisite: 11-791. The course is required for VLIS students.
LTI11796 | Question Answering Lab | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11796&SEMESTER=S17 | instructors:Mitamura, Teruko Nyberg, Eric prereq:11791 description:The Question Answering Lab provides a hands-on introduction to existing approaches to question answering (QA). Students will define their own project, with approval from the instructor. Each student will work independently. If multiple students work as a team on a particular topic, each should choose an approach that is different from the approaches used by the other students working on the same problem. Students will document their approach and progress on a wiki page that is shared with the instructor. Grading will be based on periodic and final review of the student progress as documented on the wiki.
LTI11797 | Question Answering | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11797&SEMESTER=S17 | instructors:Nyberg, Eric Mitamura, Teruko description:The Question Answering course provides a chance for hands-on, in-depth exploration of core algorithmic approaches to question answering (QA). Students will work independently or in small teams to extend or adapt existing QA modules and systems to improve overall performance on known QA datasets (e.g. TREC, CLEF, NTCIR), using best practices associated with the Open Advancement of Question Answering initiative. Each student project will evaluate one or more component algorithms on a given QA dataset and produce a conference-style paper describing the system design, experimental setup and results.
LTI11821 | Advanced Linguistics Seminar | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11821&SEMESTER=S17 | instructors:Levin, Lorraine description:None
LTI11823 | ConLanging: Lrng. Ling. &amp; Lang Tech via Constru Artif. Lang. | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11823&SEMESTER=S17 | instructors:Black, Alan Levin, Lorraine description:TBD
LTI11899 | Summarization of Documents and Interaction: Summarization of Documents and InteractionThis Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11899&SEMESTER=F16 | instructors:Rose, Carolyn description:The problem of information overload in personal communication media such as email, instant messaging, and on-line forums is a well documented phenomenon. Much work addressing this problem has been conducted separately in the human-computer interaction (HCI) community, the information sciences community, and the computational linguistics community.  However, in each case, while important advancements in scientific knowledge have been achieved, the work suffers from an elephant complex, where each community focuses mainly on just the part of the problem most visible from their own perspective.  The purpose of this course is to bring these threads together to examine the issue of managing personal communication data from an integrated perspective.
LTI11910 | Directed Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11910&SEMESTER=S17 | instructors:Frederking, Robert description:This course number documents the research being done by Masters and pre-proposal PhD students. Beginning in Fall 2001, every LTI graduate student will register for at least 24 units of 11-910 each semester, unless they are ABD (i.e., they have had a thesis proposal accepted), in which case they should register for 48 units of 11-930. The student will be expected to write a report and give a presentation at the end of the semester, documenting the research done. The report will be filed by either the faculty member or the LTI graduate program administrator.   (Until Fall 2001 this course number was used for individual study in connection with LTI project research work and was a Pass/Fail course.)
LTI11920 | Independent Study: Breadth | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11920&SEMESTER=S17 | instructors:Frederking, Robert description:This course number is intended for individual study with faculty other than a students intended thesis advisor.
LTI11925 | Independent Study: Area | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11925&SEMESTER=S17 | instructors:Frederking, Robert description:This course number is intended for individual study with the intended thesis advisor prior to acceptance of a students thesis proposal.
LTI11927 | MIIS Capstone Project | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11927&SEMESTER=F16 | instructors:Brown, Ralf description:The capstone project course is a group-oriented demonstration of student skill in one or more areas covered by the degree. Typically the result of the capstone project is a major software application. The capstone project course consists of two components.  The classroom component guides students in project planning, team management, development of requirements and design specifications, and software tools for managing group-oriented projects.  The lab component provides project-specific technical guidance and expertise, for example in the development of a question answering system, dialog, or sentiment analysis application.  Thus, each project receives two types of supervision, often from two separate members of the faculty.
LTI11928 | Masters Thesis I | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11928&SEMESTER=F16 | instructors:Frederking, Robert description:This course number is intended for last semester Masters students who wish to do an optional Masters Thesis.
LTI11929 | Masters Thesis II | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11929&SEMESTER=S17 | instructors:Frederking, Robert description:This course number is intended for last semester Masters students who wish to do an optional Masters Thesis. The student will normally have taken 11-925 Independent Study: Area of Concentration for 12 units in the preceding semester, to produce an MS Thesis Proposal.
LTI11930 | Dissertation Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11930&SEMESTER=S17 | instructors:Frederking, Robert description:This course number is intended for PhD dissertation research after acceptance of a students PhD thesis proposal.
LTI11935 | LTI Practicum | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11935&SEMESTER=S17 | instructors:Frederking, Robert description:This course is intended as an internship course for students who are doing Curricular Practical Training (CPT) as part of their graduate degree.
